\documentclass[12pt,a4paper]{article}

% ==============================
% PACKAGES
% ==============================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{xcolor}
\usepackage{titlesec}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage[ruled,vlined,french,onelanguage]{algorithm2e}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{booktabs}
\usepackage{multirow}

\pgfplotsset{compat=1.18}
\usetikzlibrary{arrows.meta, positioning, shapes.geometric}

% ==============================
% MISE EN PAGE
% ==============================
\geometry{margin=2.5cm}
\setstretch{1.15}
\setlength{\headheight}{16pt}

\definecolor{cvblue}{HTML}{2A4D69}

\titleformat{\section}{\normalfont\LARGE\bfseries\color{cvblue}}{}{0pt}{}
\titleformat{\subsection}{\normalfont\Large\bfseries\color{cvblue}}{}{0pt}{}

% Headers et footers
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\leftmark}
\fancyhead[R]{Projet TSP - Master MIASHS}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.5pt}

% ==============================
% MOTS-CLÉS ALGORITHMES
% ==============================
\SetKwData{Donnees}{Données}
\SetKw{KwRetourner}{Retourner}

\begin{document}

% ==============================
% PAGE DE GARDE
% ==============================
\begin{titlepage}
\centering
\vspace*{3cm}

{\Huge\textbf{Projet d'Optimisation}}\\[0.3cm]
{\Large\textbf{Problème du Voyageur de Commerce (TSP)}}\\[1cm]

\rule{0.6\textwidth}{1pt}\\[0.5cm]
{\LARGE\textbf{Rapport Final}}\\[0.3cm]
{\Large\textbf{Algorithmes Exacts et Heuristiques}}\\
\rule{0.6\textwidth}{1pt}\\[3cm]

{\large\textbf{Master MIASHS — IMA-UCO (2025–2026)}}\\[1cm]
{\large\textbf{Auteurs :} Matthias Jourdren / Maxence Cornu Basset / Gaëtan Pezas}\\[0.3cm]
{\large\textbf{Date :} \today}

\end{titlepage}

\newpage
\tableofcontents
\newpage
\listoffigures
\newpage

% ==============================
\section{Introduction}

Le Problème du Voyageur de Commerce (\textbf{Traveling Salesperson Problem – TSP}) est un problème classique d'optimisation combinatoire.  
Il consiste à déterminer la tournée de coût minimal permettant de visiter chaque ville exactement une fois et de revenir à la ville de départ.

Ce problème est connu pour sa difficulté algorithmique, car il appartient à la classe des problèmes \textbf{NP-difficiles}.  
Cela signifie qu'il n'existe pas d'algorithme connu capable de résoudre toutes les instances du TSP en temps polynomial.

Dans ce projet, plusieurs approches ont été implémentées afin de comparer leurs performances et leur qualité de solution :
\begin{itemize}
    \item Un algorithme \textbf{exact} garantissant l'optimalité (Branch and Bound)
    \item Des \textbf{heuristiques} rapides mais approximatives (Plus Proche Voisin, 2-opt)
    \item Une \textbf{méta-heuristique} combinant diversification et intensification (GRASP)
\end{itemize}

% ==============================
\section{Applications du TSP}

Le problème du voyageur de commerce n'est pas qu'un exercice théorique. Il trouve de nombreuses applications pratiques dans divers domaines :

\subsection{Fabrication de Circuits Imprimés (PCB)}

Dans l'industrie électronique, la fabrication de circuits imprimés nécessite de \textbf{percer des milliers de trous} sur une plaque. Le TSP permet d'optimiser le parcours de la tête de perçage pour :
\begin{itemize}
    \item Minimiser le temps de déplacement de la machine
    \item Réduire l'usure de l'équipement
    \item Augmenter la productivité
\end{itemize}

\subsection{Séquençage ADN}

En bioinformatique, le TSP est utilisé pour la \textbf{reconstruction de séquences génétiques}. Les fragments d'ADN doivent être assemblés dans le bon ordre, ce qui peut être modélisé comme un problème de tournée où :
\begin{itemize}
    \item Chaque fragment est une "ville"
    \item La distance représente le degré de chevauchement entre fragments
    \item L'objectif est de trouver l'ordre optimal de reconstruction
\end{itemize}

\subsection{Astronomie}

Les télescopes automatisés doivent observer plusieurs objets célestes durant une nuit. Le TSP permet de \textbf{planifier l'ordre des observations} pour :
\begin{itemize}
    \item Minimiser le temps de déplacement du télescope
    \item Maximiser le nombre d'observations possibles
    \item Tenir compte des contraintes temporelles (visibilité des objets)
\end{itemize}

\subsection{Autres Applications}

Le TSP trouve également des applications dans :
\begin{itemize}
    \item La \textbf{planification d'itinéraires touristiques} (visiter plusieurs sites en minimisant les déplacements)
    \item L'\textbf{optimisation de réseaux} (câblage, pipelines)
    \item La \textbf{cristallographie aux rayons X} (positionnement optimal du cristal)
\end{itemize}

\newpage
% ==============================
\section{Méthodes Implémentées}

Cette section présente les quatre approches algorithmiques implémentées pour résoudre le TSP. Nous commençons par l'algorithme exact, puis présentons les heuristiques par ordre croissant de sophistication.

% =====================================================
\subsection{Algorithme exact : Branch and Bound}

L'algorithme de Branch and Bound est la seule méthode garantissant l'\textbf{optimalité} de la solution. Il explore systématiquement l'espace des solutions possibles tout en élaguant les branches non prometteuses.

\subsubsection{Principe de fonctionnement}

L'algorithme construit récursivement des chemins partiels à partir d'une ville de départ fixée (ville 0). À chaque étape :
\begin{enumerate}
    \item On étend le chemin partiel en ajoutant une ville non visitée
    \item On calcule le coût cumulé du chemin
    \item Si ce coût dépasse la meilleure solution connue, on \textbf{élague} cette branche
    \item Sinon, on continue l'exploration récursive
\end{enumerate}

Le mécanisme d'\textbf{élagage} (pruning) est crucial : dès qu'un chemin partiel a un coût supérieur à la meilleure solution complète trouvée, on abandonne toute cette branche de l'arbre de recherche.

\subsubsection{Exemple visuel}

Considérons un graphe à 4 villes. L'arbre de recherche explore toutes les permutations possibles :

\begin{center}
\begin{tikzpicture}[
    level 1/.style={sibling distance=4cm, level distance=1.5cm},
    level 2/.style={sibling distance=2cm, level distance=1.5cm},
    level 3/.style={sibling distance=1cm, level distance=1.5cm},
    every node/.style={circle, draw, minimum size=0.8cm}
]
\node {0}
    child {node {1}
        child {node {2}
            child {node {3}}
        }
        child {node {3}
            child {node {2}}
        }
    }
    child {node {2}
        child {node {1}
            child {node[red, thick] {3}}
        }
        child {node {3}
            child {node {1}}
        }
    }
    child {node {3}
        child {node {1}
            child {node {2}}
        }
        child {node {2}
            child {node {1}}
        }
    };
\end{tikzpicture}
\end{center}

Les nœuds en rouge représentent les branches élaguées car leur coût partiel dépasse déjà la meilleure solution.

\subsubsection{Algorithme}

\begin{algorithm}[H]
\SetAlgoLined
\DontPrintSemicolon

\Donnees{Matrice des distances $D$, nombre de villes $n$}\;
$MeilleurCout \leftarrow +\infty$\;
$MeilleureTournee \leftarrow \emptyset$\;

\BlankLine
\textbf{Procédure Explorer($C_p$, $K_p$, $V_p$)}\;
\tcp{$C_p$ : chemin partiel, $K_p$ : coût partiel, $V_p$ : villes visitées}
    \If{$K_p \ge MeilleurCout$}{
        \KwRet \tcp*[r]{Élagage}
    }
    \If{$|C_p| = n$}{
        $K_{final} \leftarrow K_p + D[dernier(C_p), premier(C_p)]$
        \If{$K_{final} < MeilleurCout$}{
            $MeilleurCout \leftarrow K_{final}$\;
            $MeilleureTournee \leftarrow C_p$\;
        }
        \KwRet\;
    }
    \ForEach{ville $v \notin V_p$}{
        Explorer($C_p \cup \{v\}$, $K_p + D[dernier(C_p), v]$, $V_p \cup \{v\}$)\;
    }
Explorer([0], 0, \{0\})\;
\KwRetourner $MeilleureTournee$, $MeilleurCout$\;

\caption{Algorithme exact Branch and Bound pour le TSP}
\end{algorithm}

\newpage

\subsubsection{Complexité}

La complexité de cet algorithme est \textbf{factorielle} dans le pire des cas :
\[
\mathcal{O}(n!)
\]

\textbf{Explication détaillée :}
\begin{itemize}
    \item Pour la première ville, nous avons $n$ choix possibles
    \item Pour la deuxième ville, $(n-1)$ choix
    \item Pour la troisième ville, $(n-2)$ choix
    \item Et ainsi de suite jusqu'à 1 choix pour la dernière ville
    \item Total : $n \times (n-1) \times (n-2) \times \ldots \times 1 = n!$
\end{itemize}

\textbf{Croissance explosive :}
\begin{itemize}
    \item $10! = 3\,628\,800$ (environ 3,6 millions)
    \item $15! = 1\,307\,674\,368\,000$ (environ 1,3 billions)
    \item $20! \approx 2.4 \times 10^{18}$ (2,4 quintillions)
\end{itemize}

Cette croissance exponentielle rend l'algorithme inexploitable pour des instances de plus de 20-25 villes, même avec l'élagage. C'est pourquoi un \textbf{timeout} de 60 secondes a été imposé dans notre implémentation.

\subsubsection{Cas Pathologiques}

L'algorithme Branch and Bound devient particulièrement inefficace sur certaines configurations où le mécanisme d'élagage ne peut pas fonctionner efficacement :

\begin{itemize}
    \item \textbf{Graphes avec distances uniformes} : Lorsque toutes les distances sont très similaires, les bornes inférieures calculées sont proches du coût réel, ce qui empêche l'élagage précoce des branches. L'algorithme doit alors explorer une proportion beaucoup plus importante de l'arbre de recherche.
    
    \item \textbf{Exemple concret} : Considérons un graphe complet où toutes les distances $d_{ij} \in [99, 101]$. Dans ce cas, presque tous les chemins partiels ont des coûts similaires, et la borne inférieure ne permet pas de distinguer les branches prometteuses des autres. L'algorithme se rapproche alors d'une exploration exhaustive de $n!$ permutations.
    
    \item \textbf{Impact} : Sur de telles instances, le temps d'exécution peut être multiplié par un facteur 10 à 100 par rapport à des instances avec des distances variées, même pour un nombre de villes identique.
\end{itemize}


\newpage
% =====================================================
\subsection{Heuristique constructive : Plus proche voisin}

L'heuristique du plus proche voisin est une approche \textbf{gloutonne} qui construit une solution pas à pas en faisant à chaque étape le choix localement optimal.

\subsubsection{Principe de fonctionnement}

À partir d'une ville de départ (ville 0), l'algorithme :
\begin{enumerate}
    \item Sélectionne la ville non visitée la plus proche
    \item L'ajoute à la tournée
    \item Répète jusqu'à avoir visité toutes les villes
    \item Retourne à la ville de départ
\end{enumerate}

\subsubsection{Exemple visuel}

\begin{center}
\begin{tikzpicture}[scale=1.2]
    % Villes
    \node[circle, fill=blue!30, draw] (0) at (0,0) {0};
    \node[circle, fill=gray!30, draw] (1) at (2,1) {1};
    \node[circle, fill=gray!30, draw] (2) at (4,0) {2};
    \node[circle, fill=gray!30, draw] (3) at (3,2) {3};
    
    % Distances
    \draw[dashed, gray] (0) -- node[above] {2.2} (1);
    \draw[dashed, gray] (0) -- node[below] {4.0} (2);
    \draw[dashed, gray] (0) -- node[left] {3.6} (3);
    
    % Choix (le plus proche)
    \draw[->, thick, red] (0) -- (1);
    
    \node[below] at (2,-1) {Étape 1 : Choisir la ville la plus proche (1)};
\end{tikzpicture}
\end{center}

\subsubsection{Adaptation au TSP}

Dans notre implémentation, le graphe est représenté par une \textbf{matrice d'adjacence} contenant les distances entre toutes les paires de villes. Les villes déjà visitées sont mémorisées pour garantir que chaque sommet n'est visité qu'une seule fois.

\subsubsection{Algorithme}

\begin{algorithm}[H]
\SetAlgoLined
\DontPrintSemicolon

\Donnees{Matrice des distances $D$, nombre de villes $n$}

\BlankLine
\textbf{Initialisation :}\;
$v_{actuelle} \leftarrow 0$ \tcp*{Ville de départ}
$Tournee \leftarrow [v_{actuelle}]$\;
$VillesVisitees \leftarrow \{v_{actuelle}\}$\;
$CoutTotal \leftarrow 0$\;

\BlankLine
\textbf{Construction de la tournée :}\;
\While{$|Tournee| < n$}{
    \Indp
    \tcp{Sélectionner la ville non visitée la plus proche}
    $v_{suivante} \leftarrow$ argmin$_{v \notin VillesVisitees} D[v_{actuelle}, v]$\;

    \tcp{Mettre à jour la tournée et le coût}
    Ajouter $v_{suivante}$ à $Tournee$\;
    Ajouter $v_{suivante}$ à $VillesVisitees$\;
    $CoutTotal \leftarrow CoutTotal + D[v_{actuelle}, v_{suivante}]$\;

    \tcp{Passer à la ville suivante}
    $v_{actuelle} \leftarrow v_{suivante}$\;
    \Indm
}

\BlankLine
\textbf{Clôture de la tournée :}\;
$CoutTotal \leftarrow CoutTotal + D[v_{actuelle}, Tournee[0]]$ \tcp*{Retour à la ville de départ}

\KwRetourner $Tournee$, $CoutTotal$\;

\caption{Heuristique constructive du Plus Proche Voisin}
\end{algorithm}

\subsubsection{Complexité}

La complexité temporelle de cet algorithme est :
\[
\mathcal{O}(n^2)
\]

\textbf{Explication détaillée :}
\begin{itemize}
    \item \textbf{Boucle externe} : On doit visiter $n$ villes, donc $n$ itérations
    \item \textbf{Boucle interne} : À chaque itération, on cherche le minimum parmi les villes restantes
    \begin{itemize}
        \item Itération 1 : $(n-1)$ comparaisons
        \item Itération 2 : $(n-2)$ comparaisons
        \item $\ldots$
        \item Itération $n-1$ : 1 comparaison
    \end{itemize}
    \item \textbf{Total} : $(n-1) + (n-2) + \ldots + 1 = \frac{n(n-1)}{2} = \mathcal{O}(n^2)$
\end{itemize}

Cette complexité quadratique rend l'algorithme très rapide même pour des instances de grande taille (plusieurs milliers de villes).

\subsubsection{Limites}

L'heuristique du plus proche voisin ne garantit \textbf{pas l'optimalité}. Le choix glouton local peut mener à une mauvaise solution globale. Par exemple, choisir systématiquement la ville la plus proche peut créer des "détours" coûteux en fin de parcours.

\subsubsection{Cas Pathologiques}

L'approche gloutonne du plus proche voisin peut produire des solutions très sous-optimales sur certaines configurations géométriques :

\begin{itemize}
    \item \textbf{Configuration en "étoile"} : Considérons une instance où une ville centrale (ville 0) est très proche de toutes les autres villes, mais ces dernières sont très éloignées entre elles, disposées en cercle autour du centre.
    
    \item \textbf{Comportement de l'algorithme} : Partant de la ville 0, l'algorithme choisit une ville du cercle (par exemple ville 1). Ensuite, au lieu de continuer le tour du cercle, il peut être tenté de revenir au centre si celui-ci est plus proche que la ville suivante du cercle. Cela crée des allers-retours coûteux.
    
    \item \textbf{Exemple numérique} : 
    \begin{itemize}
        \item Distance centre-périphérie : 1 unité
        \item Distance entre villes de la périphérie : 10 unités
        \item Solution gloutonne : Allers-retours multiples (coût $\approx 2n$)
        \item Solution optimale : Tour du cercle (coût $\approx 10n$)
        \item Écart : Peut atteindre 50\% ou plus
    \end{itemize}
    
    \item \textbf{Impact pratique} : Sur les instances testées, l'écart observé varie de 5\% à 17\%, confirmant que certaines configurations géométriques pénalisent fortement cette heuristique.
\end{itemize}

% =====================================================
\subsection{Heuristique de recherche locale : 2-opt}

La recherche locale 2-opt est une méthode d'\textbf{amélioration itérative} qui part d'une solution initiale et tente de l'améliorer par des modifications locales.

\subsubsection{Principe de fonctionnement}

L'algorithme 2-opt cherche à améliorer une tournée en \textbf{inversant des segments} du parcours. Pour chaque paire d'arêtes $(i, i+1)$ et $(k, k+1)$ :
\begin{enumerate}
    \item On supprime ces deux arêtes
    \item On reconnecte en inversant le segment entre $i+1$ et $k$
    \item Si le coût diminue, on accepte la modification
    \item On répète jusqu'à ce qu'aucune amélioration ne soit possible
\end{enumerate}

\subsubsection{Exemple visuel}

\begin{center}
\begin{tikzpicture}[scale=1.5]
    % Avant
    \begin{scope}[xshift=0cm]
        \node[circle, fill=blue!30, draw] (A) at (0,0) {A};
        \node[circle, fill=blue!30, draw] (B) at (2,0) {B};
        \node[circle, fill=blue!30, draw] (C) at (2,2) {C};
        \node[circle, fill=blue!30, draw] (D) at (0,2) {D};
        
        \draw[->, thick] (A) -- (B);
        \draw[->, thick, red] (B) -- (D);
        \draw[->, thick, red] (D) -- (C);
        \draw[->, thick] (C) -- (A);
        
        \node[below] at (1,-0.5) {\textbf{Avant} : Croisement};
    \end{scope}
    
    % Après
    \begin{scope}[xshift=5cm]
        \node[circle, fill=green!30, draw] (A) at (0,0) {A};
        \node[circle, fill=green!30, draw] (B) at (2,0) {B};
        \node[circle, fill=green!30, draw] (C) at (2,2) {C};
        \node[circle, fill=green!30, draw] (D) at (0,2) {D};
        
        \draw[->, thick] (A) -- (B);
        \draw[->, thick, green!70!black] (B) -- (C);
        \draw[->, thick, green!70!black] (C) -- (D);
        \draw[->, thick] (D) -- (A);
        
        \node[below] at (1,-0.5) {\textbf{Après} : Pas de croisement};
    \end{scope}
\end{tikzpicture}
\end{center}

L'inversion du segment $[B, D]$ élimine le croisement et réduit la distance totale.

\subsubsection{Adaptation au TSP}

La tournée est représentée comme une liste ordonnée de villes. L'algorithme évalue systématiquement toutes les inversions possibles et accepte la première amélioration trouvée (stratégie \textit{first improvement}).

\subsubsection{Algorithme}

\begin{algorithm}[H]
\SetAlgoLined
\DontPrintSemicolon

\Donnees{Tournée initiale $T$, matrice des distances $D$}
$amelioration \leftarrow Vrai$\;

\BlankLine
\While{$amelioration$}{
    $amelioration \leftarrow Faux$\;
    \For{$i = 1$ \KwTo $n-2$}{
        \For{$k = i+1$ \KwTo $n-1$}{
            $T' \leftarrow$ inverser le segment $[i,k]$ de $T$\;
            \If{$Cout(T') < Cout(T)$}{
                $T \leftarrow T'$\;
                $amelioration \leftarrow Vrai$\;
                \textbf{Sortir des boucles}\;
            }
        }
    }
}

\KwRetourner $T$\;

\caption{Recherche locale 2-opt pour le TSP}
\end{algorithm}

\subsubsection{Complexité}

La complexité de l'algorithme 2-opt est :
\[
\mathcal{O}(n^2 \times k)
\]

où $k$ est le nombre d'itérations de la boucle \texttt{while}.

\textbf{Explication détaillée :}
\begin{itemize}
    \item \textbf{Boucles imbriquées} : Il y a $\binom{n}{2} = \frac{n(n-1)}{2} = \mathcal{O}(n^2)$ paires d'arêtes possibles à tester
    \item \textbf{Nombre d'itérations} : Le nombre de fois où on trouve une amélioration dépend de :
    \begin{itemize}
        \item La qualité de la solution initiale
        \item La structure de l'instance
        \item Dans le pire cas, $k$ peut être $\mathcal{O}(n)$ ou plus
    \end{itemize}
    \item \textbf{Complexité totale} : $\mathcal{O}(n^2 \times k)$
\end{itemize}

\textbf{Note importante :} La complexité n'est \textbf{pas} simplement $\mathcal{O}(n^2)$. Le facteur $k$ (nombre d'améliorations successives) peut être significatif.

\subsubsection{Optimum local}

L'algorithme 2-opt converge vers un \textbf{optimum local} : une solution qui ne peut pas être améliorée par des inversions 2-opt, mais qui n'est pas nécessairement la solution optimale globale.

\subsubsection{Cas Pathologiques}

La recherche locale 2-opt peut se bloquer dans des optimums locaux éloignés de l'optimum global :

\begin{itemize}
    \item \textbf{Optimums locaux profonds} : Certaines configurations de tournées nécessitent de modifier simultanément plus de 2 arêtes pour atteindre une meilleure solution. Or, 2-opt ne peut modifier que 2 arêtes à la fois, ce qui crée des "barrières" infranchissables.
    
    \item \textbf{Exemple concret} : Considérons une tournée avec plusieurs croisements imbriqués. Pour démêler ces croisements, il faudrait parfois effectuer 3 ou 4 inversions simultanées (3-opt, 4-opt), ce qui est impossible avec 2-opt.
    
    \item \textbf{Dépendance à la solution initiale} : La qualité de la solution finale dépend fortement de la solution de départ. Une mauvaise solution initiale (générée par l'heuristique constructive) peut mener à un optimum local médiocre.
    
    \item \textbf{Impact observé} : Sur les instances testées, 2-opt atteint l'optimal sur les petites instances (17 villes) mais peut rester à 3-4\% de l'optimal sur les instances moyennes, indiquant la présence d'optimums locaux.
    
    \item \textbf{Limitation fondamentale} : 2-opt ne peut pas "sauter" par-dessus des barrières d'optimum local. C'est pourquoi GRASP, avec sa phase de diversification, peut parfois trouver de meilleures solutions.
\end{itemize}

% =====================================================
\subsection{Méta-heuristique : GRASP}

GRASP (\textit{Greedy Randomized Adaptive Search Procedure}) est une méta-heuristique combinant \textbf{diversification} et \textbf{intensification}.

\subsubsection{Principe de fonctionnement}

GRASP fonctionne en deux phases répétées sur plusieurs itérations :

\begin{enumerate}
    \item \textbf{Phase de construction randomisée} : Construire une solution de manière semi-gloutonne avec un élément aléatoire
    \item \textbf{Phase d'amélioration locale} : Améliorer la solution avec 2-opt
\end{enumerate}

La meilleure solution trouvée sur toutes les itérations est conservée.

\subsubsection{Diagramme du processus}

\begin{center}
\begin{tikzpicture}[
    node distance=2.5cm,
    box/.style={rectangle, draw, fill=blue!20, text width=4cm, align=center, rounded corners, minimum height=1.2cm},
    decision/.style={diamond, draw, fill=yellow!20, text width=3cm, align=center, aspect=2, minimum height=1.5cm}
]
    \node[box] (start) {Début};
    \node[box, below of=start] (construct) {Construction\\randomisée\\(RCL + $\alpha$)};
    \node[box, below of=construct] (improve) {Amélioration\\locale\\(2-opt)};
    \node[decision, below of=improve, node distance=3cm] (better) {Meilleure\\solution ?};
    \node[box, below of=better, node distance=3.5cm] (update) {Mettre à jour\\meilleur};
    \node[decision, right of=better, node distance=6.5cm] (continue) {Plus\\d'itérations ?};
    \node[box, below of=continue, node distance=3.5cm] (end) {Retourner\\meilleur};
    
    \draw[->] (start) -- (construct);
    \draw[->] (construct) -- (improve);
    \draw[->] (improve) -- (better);
    \draw[->] (better) -- node[right] {Oui} (update);
    \draw[->] (better) -- node[above] {Non} (continue);
    \draw[->] (update) -| (continue);
    \draw[->] (continue) -- node[right] {Non} (end);
    \draw[->] (continue) |- node[above, near start] {Oui} (construct);
\end{tikzpicture}
\end{center}

\newpage
\subsubsection{Liste Restreinte de Candidats (RCL)}

Le paramètre $\alpha \in [0, 1]$ contrôle le compromis entre choix glouton et diversification :
\begin{itemize}
    \item $\alpha = 0$ : Purement glouton (toujours choisir le meilleur)
    \item $\alpha = 1$ : Complètement aléatoire
    \item $\alpha \in ]0, 1[$ : Compromis (valeur typique : 0.3)
\end{itemize}

La RCL contient les villes dont la distance est dans l'intervalle :
\[
[C_{min}, C_{min} + \alpha(C_{max} - C_{min})]
\]

\subsubsection{Algorithme}

\begin{algorithm}[H]
\SetAlgoLined
\DontPrintSemicolon

\Donnees{Matrice des distances $D$, paramètre $\alpha$, nombre d'itérations $MaxIter$}
$MeilleurCout \leftarrow +\infty$\;
$MeilleureSolution \leftarrow \emptyset$\;

\BlankLine
\For{$iter = 1$ \KwTo $MaxIter$}{

    \BlankLine
    \textit{// Phase 1 : Construction gloutonne randomisée}\;
    Choisir une ville de départ (ville 0)\;
    $T \leftarrow [v_{depart}]$\;
    \While{$|T| < n$}{
        $Candidats \leftarrow$ villes non visitées\;
        $C_{min}, C_{max} \leftarrow$ coûts min et max depuis la ville courante\;
        $LRC \leftarrow \{v \in Candidats \mid D \le C_{min} + \alpha(C_{max} - C_{min})\}$\;
        $v_{choisie} \leftarrow$ choix aléatoire dans $LRC$\;
        Ajouter $v_{choisie}$ à $T$\;
    }

    \BlankLine
    \textit{// Phase 2 : Intensification}\;
    $T_{opt} \leftarrow$ RechercheLocale2Opt($T$)\;

    \BlankLine
    \If{$Cout(T_{opt}) < MeilleurCout$}{
        $MeilleurCout \leftarrow Cout(T_{opt})$\;
        $MeilleureSolution \leftarrow T_{opt}$\;
    }
}

\KwRetourner $MeilleureSolution$\;

\caption{Méta-heuristique GRASP pour le TSP}
\end{algorithm}

\newpage
\subsubsection{Complexité}

La complexité de GRASP est :
\[
\mathcal{O}(I_{max} \times n^2 \times k)
\]

\textbf{Explication détaillée :}
\begin{itemize}
    \item $I_{max}$ : Nombre d'itérations de GRASP (typiquement 100-1000)
    \item Pour chaque itération :
    \begin{itemize}
        \item \textbf{Construction} : $\mathcal{O}(n^2)$ (similaire au plus proche voisin)
        \item \textbf{Amélioration locale} : $\mathcal{O}(n^2 \times k)$ (2-opt)
    \end{itemize}
    \item \textbf{Total par itération} : $\mathcal{O}(n^2 + n^2 \times k) = \mathcal{O}(n^2 \times k)$
    \item \textbf{Total global} : $\mathcal{O}(I_{max} \times n^2 \times k)$
\end{itemize}

En pratique, $I_{max}$ est fixé à une valeur raisonnable (100 dans notre implémentation), ce qui rend GRASP utilisable même pour des instances de taille moyenne.

\subsubsection{Cas Pathologiques}

GRASP peut être inefficace dans certaines situations où la randomisation n'apporte pas la diversité nécessaire :

\begin{itemize}
    \item \textbf{Paramètre $\alpha$ mal calibré} : Le paramètre $\alpha$ contrôle le compromis entre choix glouton et diversification. Un $\alpha$ trop petit ($\alpha \approx 0$) rend GRASP quasi-identique à l'heuristique constructive répétée, perdant l'avantage de la diversification. À l'inverse, un $\alpha$ trop grand ($\alpha \approx 1$) génère des solutions trop aléatoires de mauvaise qualité.
    
    \item \textbf{Instances avec structure dominante} : Sur certaines instances où une structure optimale est très marquée (par exemple, villes alignées), la randomisation peut nuire en éloignant systématiquement l'algorithme de cette structure évidente.
    
    \item \textbf{Nombre d'itérations insuffisant} : Sur de grandes instances, 100 itérations peuvent ne pas suffire à explorer suffisamment l'espace de solutions. Comme observé sur l'instance 439.in, GRASP n'a pas terminé dans le délai imparti avec 100 itérations, révélant un problème de scalabilité.
    
    \item \textbf{Impact observé} : Sur l'instance 439.in (439 villes), GRASP atteint le timeout de 600 secondes sans produire de solution, alors que LocalSearch termine en 292 secondes. Cela montre que le nombre fixe de 100 itérations n'est pas adapté à toutes les tailles d'instances.
    
    \item \textbf{Recommandation} : Pour les grandes instances, il faudrait adapter dynamiquement le nombre d'itérations en fonction de $n$, par exemple $I_{max} = \max(10, 1000/n)$.
\end{itemize}

\clearpage
% ==============================
\section{Méthodologie de Test}

\subsection{Instances de Test}

Trois instances ont été utilisées pour les tests :

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Instance} & \textbf{Nombre de villes} & \textbf{Type} \\
\midrule
17.in & 17 & Petite instance \\
51.in & 51 & Instance moyenne \\
52.in & 52 & Instance moyenne \\
439.in & 439 & Instance grande \\
\bottomrule
\end{tabular}
\caption{Instances de test utilisées}
\label{tab:instances}
\end{table}

Ces instances sont des graphes complets pondérés où chaque ville est connectée à toutes les autres avec des distances euclidiennes.

\subsubsection{Origine et Génération des Instances}

Les instances utilisées dans ce projet sont des graphes euclidiens générés selon le protocole suivant :

\begin{itemize}
    \item \textbf{Type de graphe} : Graphes complets euclidiens en 2D
    \item \textbf{Méthode de génération} : Chaque ville est représentée par un point $(x, y)$ dans un plan cartésien. Les coordonnées sont générées aléatoirement dans un espace délimité (par exemple $[0, 1000] \times [0, 1000]$).
    \item \textbf{Calcul des distances} : La distance entre deux villes $i$ et $j$ est calculée selon la distance euclidienne :
    \[
    d_{ij} = \sqrt{(x_i - x_j)^2 + (y_i - y_j)^2}
    \]
    \item \textbf{Format des fichiers} : Les fichiers d'instance (.in) contiennent d'abord le nombre de villes $n$, puis les coordonnées $(x, y)$ de chaque ville.
    \item \textbf{Choix des tailles} : Les tailles d'instances ont été choisies pour couvrir différents régimes de complexité :
    \begin{itemize}
        \item 17 villes : Petite instance permettant à l'algorithme exact de terminer
        \item 51-52 villes : Instances moyennes où l'algorithme exact atteint le timeout
        \item 439 villes : Grande instance pour tester la scalabilité des heuristiques
    \end{itemize}
\end{itemize}

Cette méthode de génération garantit des instances réalistes où les distances respectent l'inégalité triangulaire, ce qui est caractéristique de nombreux problèmes pratiques de TSP.

\subsection{Paramètres des Algorithmes}

\begin{itemize}
    \item \textbf{Branch and Bound} : Timeout de 60 secondes pour éviter des temps d'exécution trop longs
    \item \textbf{Plus Proche Voisin} : Départ fixé à la ville 0
    \item \textbf{2-opt} : Solution initiale obtenue par Plus Proche Voisin
    \item \textbf{GRASP} : 
    \begin{itemize}
        \item Nombre d'itérations : 100
        \item Paramètre $\alpha$ : 0.3
        \item Amélioration locale : 2-opt
    \end{itemize}
\end{itemize}

\subsection{Environnement d'Exécution}

Les tests ont été effectués sur :
\begin{itemize}
    \item \textbf{Système d'exploitation} : macOS
    \item \textbf{Langage} : Python 3
    \item \textbf{Processeur} : Puce M1
\end{itemize}

\subsection{Métriques Évaluées}

Pour chaque algorithme et chaque instance, nous mesurons :
\begin{enumerate}
    \item \textbf{Coût de la tournée} : Distance totale parcourue
    \item \textbf{Temps d'exécution} : Durée en secondes
    \item \textbf{Écart à l'optimal} : Pourcentage de différence avec la meilleure solution connue
    \item \textbf{Ratio qualité/temps} : Compromis entre qualité de solution et rapidité
\end{enumerate}

\clearpage
% ==============================
\section{Analyse des Résultats}

Cette section présente une analyse détaillée des performances comparées des différentes méthodes implémentées.

\subsection{Résultats Bruts}

Le tableau suivant présente les résultats obtenus pour chaque algorithme sur les trois instances de test :

\begin{table}[H]
\centering
\begin{tabular}{llrrr}
\toprule
\textbf{Instance} & \textbf{Algorithme} & \textbf{Coût} & \textbf{Temps (s)} & \textbf{Statut} \\
\midrule
\multirow{4}{*}{17.in} & Exact & 2085.0 & 18.72 & Optimal \\
                       & Constructive & 2187.0 & 0.024 & Heuristique \\
                       & LocalSearch & 2085.0 & 0.025 & Optimal \\
                       & GRASP\_LS & 2085.0 & 0.069 & Optimal \\
\midrule
\multirow{4}{*}{51.in} & Exact & 449.0 & 60.02 & Timeout \\
                       & Constructive & 511.0 & 0.025 & Heuristique \\
                       & LocalSearch & 438.0 & 0.096 & Meilleur \\
                       & GRASP\_LS & 439.0 & 3.38 & Très bon \\
\midrule
\multirow{4}{*}{52.in} & Exact & 8021.0 & 60.03 & Timeout \\
                       & Constructive & 8980.0 & 0.024 & Heuristique \\
                       & LocalSearch & 7967.0 & 0.064 & Très bon \\
                       & GRASP\_LS & 7672.0 & 4.36 & Meilleur \\
\bottomrule
\end{tabular}
\caption{Résultats détaillés par algorithme et instance}
\label{tab:results}
\end{table}

\newpage
\subsection{Analyse par Instance}

\subsubsection{Instance 17.in (17 villes)}

Sur cette petite instance :
\begin{itemize}
    \item \textbf{Branch and Bound} trouve l'optimal (2085) en 18.72 secondes
    \item \textbf{LocalSearch} et \textbf{GRASP} atteignent également l'optimal
    \item \textbf{Constructive} donne une solution 4.9\% plus coûteuse (2187 vs 2085)
    \item Les heuristiques sont \textbf{780 fois plus rapides} que l'algorithme exact
\end{itemize}

\subsubsection{Instance 51.in (51 villes)}

Sur cette instance moyenne :
\begin{itemize}
    \item \textbf{Branch and Bound} atteint le timeout (60s) avec une solution de coût 449
    \item \textbf{LocalSearch} obtient le meilleur résultat (438) en seulement 0.096s
    \item \textbf{GRASP} est très proche (439) avec un temps légèrement supérieur (3.38s)
    \item \textbf{Constructive} donne une solution 16.7\% plus coûteuse (511 vs 438)
\end{itemize}

\subsubsection{Instance 52.in (52 villes)}

Sur cette instance moyenne :
\begin{itemize}
    \item \textbf{Branch and Bound} atteint le timeout avec une solution de coût 8021
    \item \textbf{GRASP} obtient le meilleur résultat (7672) en 4.36 secondes
    \item \textbf{LocalSearch} est très proche (7967) et beaucoup plus rapide (0.064s)
    \item \textbf{Constructive} donne une solution 17\% plus coûteuse (8980 vs 7672)
\end{itemize}

\newpage
\subsection{Comparaison Globale des Coûts}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../results/plots/comparison_cost.png}
    \caption{Comparaison du coût de la tournée par algorithme}
    \label{fig:comparison_cost}
\end{figure}

Le graphique ci-dessus montre clairement que :
\begin{itemize}
    \item Les méthodes d'amélioration (\textbf{LocalSearch} et \textbf{GRASP}) surpassent systématiquement la méthode constructive
    \item Sur les petites instances, toutes les méthodes (sauf Constructive) atteignent l'optimal
    \item Sur les instances moyennes, \textbf{GRASP} tend à donner les meilleures solutions
\end{itemize}

\newpage
\subsection{Comparaison Globale des Temps}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{../results/plots/comparison_time.png}
    \caption{Comparaison du temps d'exécution par algorithme (échelle logarithmique)}
    \label{fig:comparison_time}
\end{figure}

L'analyse des temps d'exécution révèle :
\begin{itemize}
    \item \textbf{Branch and Bound} : Explosion combinatoire évidente, timeout atteint dès 51 villes
    \item \textbf{Constructive} : Quasi-instantané ($\sim$0.024s), indépendant de la taille
    \item \textbf{LocalSearch} : Très rapide ($\sim$0.025-0.096s), excellent compromis
    \item \textbf{GRASP} : Temps raisonnable (0.07-4.36s), acceptable pour la qualité obtenue
\end{itemize}

\bigskip
\textbf{Synthèse :} L'analyse croisée des coûts et des temps d'exécution révèle une priorité d'utilisation des algorithmes. L'algorithme exact Branch and Bound, bien que garantissant l'optimalité, devient rapidement inexploitable au-delà de 20 villes en raison de sa complexité factorielle. L'heuristique constructive, malgré sa rapidité exceptionnelle, produit des solutions de qualité insuffisante (écarts de 5\% à 17\%). C'est donc vers les méthodes d'amélioration locale que notre attention se porte : \textbf{LocalSearch (2-opt)} émerge comme le meilleur compromis qualité-temps, atteignant ou s'approchant de l'optimal en moins de 0.1 seconde. GRASP, bien que légèrement plus coûteuse en temps (jusqu'à 4.36s), se distingue sur les instances moyennes où sa phase de diversification lui permet de trouver les meilleures solutions absolues. Cette analyse nous conduit à privilégier \textbf{LocalSearch pour les applications nécessitant une réponse rapide} et \textbf{GRASP lorsque la qualité de la solution prime sur le temps de calcul}.

\subsection{Analyse Détaillée par Algorithme}

\subsubsection{Performance de Branch and Bound}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{../results/plots/performance_Exact.png}
    \caption{Performance de l'algorithme Branch and Bound}
    \label{fig:perf_exact}
\end{figure}

L'algorithme exact montre :
\begin{itemize}
    \item \textbf{Garantie d'optimalité} sur les petites instances
    \item \textbf{Explosion du temps} : de 18.72s (17 villes) à timeout (51+ villes)
    \item \textbf{Limite pratique} : environ 20-25 villes maximum
\end{itemize}

\subsubsection{Performance de Plus Proche Voisin}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{../results/plots/performance_Constructive.png}
    \caption{Performance de l'heuristique constructive}
    \label{fig:perf_constructive}
\end{figure}

L'heuristique constructive montre :
\begin{itemize}
    \item \textbf{Rapidité exceptionnelle} : toujours sous 0.025s
    \item \textbf{Qualité variable} : écart de 5\% à 17\% par rapport à l'optimal
    \item \textbf{Utilité} : excellente solution initiale pour les méthodes d'amélioration
\end{itemize}

\subsubsection{Performance de 2-opt}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{../results/plots/performance_LocalSearch.png}
    \caption{Performance de la recherche locale 2-opt}
    \label{fig:perf_local}
\end{figure}

La recherche locale montre :
\begin{itemize}
    \item \textbf{Excellent compromis} qualité/temps
    \item \textbf{Amélioration significative} par rapport à la solution initiale
    \item \textbf{Rapidité} : toujours sous 0.1s
    \item \textbf{Résultats} : optimal ou très proche sur toutes les instances
\end{itemize}

\subsubsection{Performance de GRASP}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{../results/plots/performance_GRASP_LS.png}
    \caption{Performance de la méta-heuristique GRASP}
    \label{fig:perf_grasp}
\end{figure}

GRASP montre :
\begin{itemize}
    \item \textbf{Meilleures solutions} sur les instances moyennes
    \item \textbf{Robustesse} : performances consistantes
    \item \textbf{Temps acceptable} : 0.07s à 4.36s
    \item \textbf{Diversification efficace} : explore mieux l'espace de solutions
\end{itemize}

\subsection{Comparaison Détaillée par Instance}

\subsubsection{Instance 17.in}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{../results/plots/instance_17.in.png}
    \caption{Comparaison détaillée sur l'instance 17.in}
    \label{fig:inst_17}
\end{figure}

\subsubsection{Instance 51.in}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{../results/plots/instance_51.in.png}
    \caption{Comparaison détaillée sur l'instance 51.in}
    \label{fig:inst_51}
\end{figure}

\subsubsection{Instance 52.in}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{../results/plots/instance_52.in.png}
    \caption{Comparaison détaillée sur l'instance 52.in}
    \label{fig:inst_52}
\end{figure}

\subsection{Tableau Comparatif des Écarts}

\begin{table}[H]
\centering
\begin{tabular}{lrrr}
\toprule
\textbf{Algorithme} & \textbf{17.in} & \textbf{51.in} & \textbf{52.in} \\
\midrule
Exact & 0\% (optimal) & - & - \\
Constructive & +4.9\% & +16.7\% & +17.0\% \\
LocalSearch & 0\% (optimal) & 0\% (meilleur) & +3.8\% \\
GRASP\_LS & 0\% (optimal) & +0.2\% & 0\% (meilleur) \\
\bottomrule
\end{tabular}
\caption{Écart par rapport à la meilleure solution connue}
\label{tab:gaps}
\end{table}

\subsection{Analyse Statistique}

\begin{table}[H]
\centering
\begin{tabular}{lrrrr}
\toprule
\textbf{Algorithme} & \textbf{Coût moyen} & \textbf{Temps moyen (s)} & \textbf{Ratio Q/T} \\
\midrule
Exact & 3518.3 & 46.25 & 76.1 \\
Constructive & 3892.7 & 0.024 & 162197.9 \\
LocalSearch & 3496.7 & 0.062 & 56398.4 \\
GRASP\_LS & 3398.7 & 2.605 & 1304.5 \\
\bottomrule
\end{tabular}
\caption{Statistiques moyennes sur toutes les instances}
\label{tab:stats}
\end{table}

\newpage
\textbf{Observations :}
\begin{itemize}
    \item \textbf{GRASP} obtient le meilleur coût moyen (3398.7)
    \item \textbf{Constructive} est le plus rapide mais avec la moins bonne qualité
    \item \textbf{LocalSearch} offre le meilleur ratio qualité/temps
\end{itemize}

\subsection{Validation de la Complexité Théorique}

Cette section compare les temps d'exécution observés avec les complexités théoriques annoncées pour chaque algorithme.

\subsubsection{Analyse de la Croissance du Temps d'Exécution}

Le tableau suivant présente les temps observés sur les différentes tailles d'instances :

\begin{table}[H]
\centering
\begin{tabular}{lrrrr}
\toprule
\textbf{Algorithme} & \textbf{17 villes} & \textbf{51 villes} & \textbf{52 villes} & \textbf{439 villes} \\
\midrule
Exact & 18.72s & 60s (timeout) & 60s (timeout) & 600s (timeout) \\
Constructive & 0.024s & 0.025s & 0.024s & 0.05s \\
LocalSearch & 0.025s & 0.096s & 0.064s & 292.38s \\
GRASP & 0.069s & 3.38s & 4.36s & 600s (timeout) \\
\bottomrule
\end{tabular}
\caption{Temps d'exécution observés en fonction de la taille}
\label{tab:time_observed}
\end{table}

\subsubsection{Validation par Algorithme}

\paragraph{Branch and Bound - $\mathcal{O}(n!)$}

La complexité factorielle est clairement confirmée par l'explosion du temps d'exécution :
\begin{itemize}
    \item 17 villes : 18.72 secondes
    \item 51 villes : Timeout à 60 secondes (facteur $>3\times$)
    \item Croissance : De 17 à 51 villes (facteur 3), le temps devrait être multiplié par $51!/17! \approx 10^{42}$, ce qui est effectivement inexploitable
\end{itemize}

\textbf{Conclusion} : La complexité factorielle est validée. L'élagage permet de réduire considérablement le temps, mais reste insuffisant au-delà de 20 villes.

\paragraph{Heuristique Constructive - $\mathcal{O}(n^2)$}

La complexité quadratique est confirmée par la stabilité du temps :
\begin{itemize}
    \item Ratio théorique 17→51 : $(51/17)^2 = 9$
    \item Ratio observé : $0.025/0.024 \approx 1.04$
    \item Ratio théorique 17→439 : $(439/17)^2 \approx 666$
    \item Ratio observé : $0.05/0.024 \approx 2.08$
\end{itemize}

\textbf{Observation} : Les temps sont quasi-constants car les instances testées sont petites. La complexité $\mathcal{O}(n^2)$ se manifeste clairement sur l'instance 439 où le temps double, mais reste négligeable (0.05s).

\paragraph{LocalSearch (2-opt) - $\mathcal{O}(n^2 \times k)$}

La complexité dépend du facteur $k$ (nombre d'améliorations) :
\begin{itemize}
    \item 17→51 villes : Temps multiplié par $\approx 3.8$ (0.025s → 0.096s)
    \item 17→439 villes : Temps multiplié par $\approx 11\,695$ (0.025s → 292s)
    \item Ratio théorique sans $k$ : $(439/17)^2 \approx 666$
    \item Ratio observé : $11\,695$ → Le facteur $k$ augmente avec $n$
\end{itemize}

\textbf{Conclusion} : La complexité $\mathcal{O}(n^2 \times k)$ est validée. Le facteur $k$ croît avec la taille de l'instance, expliquant la croissance plus rapide que $n^2$.

\paragraph{GRASP - $\mathcal{O}(I_{max} \times n^2 \times k)$}

Avec $I_{max} = 100$ fixe :
\begin{itemize}
    \item 17→51 villes : Temps multiplié par $\approx 49$ (0.069s → 3.38s)
    \item 17→52 villes : Temps multiplié par $\approx 63$ (0.069s → 4.36s)
    \item Ratio théorique : $(51/17)^2 \times 100 = 900$ (en supposant $k$ constant)
    \item Écart : Le temps observé est inférieur car $k$ diminue avec les itérations
\end{itemize}

\textbf{Conclusion} : La complexité linéaire en $I_{max}$ est validée. Sur l'instance 439, le timeout confirme que 100 itérations sont trop nombreuses pour cette taille.

\subsubsection{Synthèse de la Validation}

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Algorithme} & \textbf{Complexité théorique} & \textbf{Validation} \\
\midrule
Exact & $\mathcal{O}(n!)$ & Validé : Croissance factorielle confirmée \\
Constructive & $\mathcal{O}(n^2)$ & Validé : Croissance quadratique confirmée \\
LocalSearch & $\mathcal{O}(n^2 \times k)$ & Validé : Facteur $k$ croissant avec $n$ \\
GRASP & $\mathcal{O}(I_{max} \times n^2 \times k)$ & Validé : Linéaire en $I_{max}$ confirmée \\
\bottomrule
\end{tabular}
\caption{Validation des complexités théoriques}
\label{tab:complexity_validation}
\end{table}

Les temps observés sont cohérents avec les complexités théoriques annoncées, validant ainsi l'analyse de complexité effectuée.

\subsection{Synthèse Comparative}

\begin{table}[H]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Critère} & \textbf{Exact} & \textbf{Constructive} & \textbf{LocalSearch} & \textbf{GRASP} \\
\midrule
Optimalité & +++  & -   & ++  & +++ \\
Rapidité   & -    & +++ & +++ & ++  \\
Scalabilité & -   & +++ & +++ & ++  \\
Robustesse & +++  & -   & ++  & +++ \\
\midrule
\textbf{Global} & ++ & ++ & +++ & +++ \\
\bottomrule
\end{tabular}
\caption{Évaluation qualitative des algorithmes}
\label{tab:qualitative}
\end{table}

\clearpage
% ==============================
\section{Tests sur Instance de Grande Taille (439.in)}

Cette section présente les résultats obtenus sur l'instance 439.in, une instance de grande taille comportant \textbf{439 villes}. Ce test permet d'évaluer la \textbf{scalabilité} des algorithmes et de mettre en évidence leurs limites pratiques face à des problèmes de dimension réelle.

\subsection{Contexte et Objectif}

Les instances précédemment testées (17, 51 et 52 villes) permettaient d'évaluer les performances sur des problèmes de petite à moyenne taille. L'instance 439.in représente un saut significatif en termes de complexité :
\begin{itemize}
    \item \textbf{Espace de recherche} : $(439-1)! \approx 10^{1000}$ permutations possibles
    \item \textbf{Matrice de distances} : $439 \times 439 = 192\,721$ distances à considérer
    \item \textbf{Timeout} : 600 secondes (10 minutes) pour limiter les temps d'exécution
\end{itemize}

Ce test permet de répondre à la question : \textit{Quels algorithmes restent utilisables sur des instances de taille réelle ?}

\subsection{Résultats Expérimentaux}

\begin{table}[H]
\centering
\begin{tabular}{lrrrl}
\toprule
\textbf{Algorithme} & \textbf{Temps (s)} & \textbf{Coût} & \textbf{Statut} & \textbf{Amélioration} \\
\midrule
Exact & 600.00 & --- & Timeout & --- \\
Constructive & 0.05 & 131\,281 & Succès & Référence \\
LocalSearch & 292.38 & 113\,210 & Succès & \textcolor{green!60!black}{-13.8\%} \\
GRASP\_LS & 600.00 & --- & Timeout & --- \\
\bottomrule
\end{tabular}
\caption{Résultats sur l'instance 439.in (439 villes, timeout 600s)}
\label{tab:results_439}
\end{table}

\subsection{Analyse Détaillée}

\subsubsection{Algorithme Exact (Branch and Bound)}

Comme attendu, l'algorithme exact \textbf{n'a pas terminé} dans le délai imparti de 600 secondes. Sa complexité factorielle $\mathcal{O}(n!)$ rend toute exploration exhaustive impossible au-delà de 20-25 villes. Ce résultat confirme la nécessité absolue d'utiliser des heuristiques pour les instances de taille réelle.

\subsubsection{Heuristique Constructive (Plus Proche Voisin)}

L'heuristique constructive maintient ses performances exceptionnelles en termes de rapidité :
\begin{itemize}
    \item \textbf{Temps d'exécution} : 0.05 seconde (quasi-instantané)
    \item \textbf{Coût obtenu} : 131\,281
    \item \textbf{Complexité} : $\mathcal{O}(n^2) = \mathcal{O}(439^2) \approx 192\,000$ opérations
\end{itemize}

Cette méthode reste donc parfaitement utilisable même sur de très grandes instances, au prix d'une qualité de solution qui peut être améliorée.

\subsubsection{Recherche Locale (2-opt)}

La recherche locale se distingue comme \textbf{le seul algorithme d'amélioration} ayant terminé dans le temps imparti :
\begin{itemize}
    \item \textbf{Temps d'exécution} : 292.38 secondes (environ 5 minutes)
    \item \textbf{Coût obtenu} : 113\,210
    \item \textbf{Amélioration} : -13.8\% par rapport à la solution constructive
    \item \textbf{Gain absolu} : 18\,071 unités de distance économisées
\end{itemize}

Ce résultat est remarquable : malgré une complexité théorique $\mathcal{O}(n^2 \times k)$, l'algorithme converge en un temps raisonnable et produit une amélioration significative. La stratégie \textit{first improvement} (accepter la première amélioration trouvée) s'avère efficace pour limiter le nombre d'itérations.

\subsubsection{Méta-heuristique GRASP}

GRASP \textbf{n'a pas terminé} dans le délai de 600 secondes. Plusieurs facteurs expliquent ce timeout :
\begin{itemize}
    \item \textbf{Nombre d'itérations} : 100 itérations configurées
    \item \textbf{Coût par itération} : Construction randomisée ($\mathcal{O}(n^2)$) + 2-opt ($\mathcal{O}(n^2 \times k)$)
    \item \textbf{Temps estimé par itération} : Si 2-opt prend ~5 minutes, GRASP nécessiterait $100 \times 5 = 500$ minutes
\end{itemize}

Ce résultat met en évidence une \textbf{limite de scalabilité} de GRASP : le nombre d'itérations doit être adapté à la taille de l'instance. Pour des instances de 400+ villes, il faudrait réduire le nombre d'itérations ou utiliser un timeout par itération.

\subsection{Observations Clés}

\begin{enumerate}
    \item \textbf{Seul LocalSearch termine avec amélioration} : Sur cette grande instance, la recherche locale 2-opt est le seul algorithme d'amélioration qui parvient à terminer et à produire une solution significativement meilleure que la solution constructive.
    
    \item \textbf{Limite de GRASP} : La méta-heuristique GRASP, qui excellait sur les instances moyennes (51-52 villes), atteint ses limites sur les grandes instances sans adaptation de ses paramètres.
    
    \item \textbf{Compromis qualité/temps} : LocalSearch offre le meilleur compromis avec une amélioration de 13.8\% en 5 minutes, ce qui reste acceptable pour de nombreuses applications pratiques.
    
    \item \textbf{Importance de l'adaptation} : Ces résultats soulignent l'importance d'adapter les paramètres algorithmiques (nombre d'itérations, timeout) à la taille de l'instance traitée.
\end{enumerate}

\subsection{Recommandations pour les Grandes Instances}

Sur la base de ces résultats, pour des instances de 400+ villes :
\begin{itemize}
    \item \textbf{Solution rapide} : Utiliser l'heuristique constructive seule (< 0.1s)
    \item \textbf{Meilleur compromis} : Utiliser LocalSearch avec timeout adapté (5-10 minutes)
    \item \textbf{GRASP adapté} : Réduire le nombre d'itérations à 10-20 au lieu de 100
    \item \textbf{Algorithme exact} : À éviter absolument, inexploitable au-delà de 25 villes
\end{itemize}

\clearpage
% ==============================
\section{Conclusion}

Ce projet a permis d'explorer et de comparer différents paradigmes de résolution du Problème du Voyageur de Commerce (TSP). L'étude comparative des performances des algorithmes implémentés sur les instances de référence (17, 51 et 52 villes) conduit aux constats suivants :

\subsection{Synthèse des Résultats}

\begin{itemize}
    \item \textbf{L'algorithme Branch and Bound} est indispensable pour garantir l'optimalité sur de très petites instances (moins de 20 villes), mais sa complexité factorielle $\mathcal{O}(n!)$ le rend rapidement inexploitable. Le timeout de 60 secondes est atteint dès 51 villes.
    
    \item \textbf{L'heuristique constructive} du plus proche voisin offre une excellente réactivité (environ 0.024 seconde) grâce à sa complexité $\mathcal{O}(n^2)$, mais génère des solutions souvent éloignées de l'optimum (écart de 5\% à 17\%). Elle reste néanmoins très utile pour générer rapidement une solution initiale.
    
    \item \textbf{La recherche locale (2-opt)} permet d'améliorer significativement les solutions initiales avec un surcoût computationnel très faible (0.025 à 0.096 seconde). Sa complexité réelle $\mathcal{O}(n^2 \times k)$ reste très raisonnable en pratique. Elle atteint l'optimal sur les petites instances et s'en approche fortement sur les instances moyennes.
    
    \item \textbf{La méta-heuristique GRASP} combine efficacement diversification (phase constructive randomisée) et intensification (recherche locale 2-opt). Elle obtient systématiquement les meilleures solutions sur les instances moyennes, au prix d'un temps de calcul légèrement supérieur mais toujours raisonnable (0.07 à 4.36 secondes).
\end{itemize}

\subsection{Élection de la Meilleure Méthode}

Au regard des instances de référence testées (17, 51 et 52 villes), deux méthodes se distinguent selon le contexte :

\paragraph{Pour la qualité de solution :} La méta-heuristique \textbf{GRASP\_LS} s'impose comme la méthode la plus performante. Sur les instances testées, elle atteint :
\begin{itemize}
    \item L'optimal sur l'instance 17.in (2085)
    \item Le meilleur résultat sur l'instance 52.in (7672, soit 4\% mieux que LocalSearch)
    \item Un résultat quasi-optimal sur l'instance 51.in (439 vs 438)
\end{itemize}

\paragraph{Pour le compromis qualité/temps :} La \textbf{recherche locale 2-opt} offre le meilleur rapport performance/rapidité. Elle produit des solutions de très bonne qualité (optimales ou très proches) en un temps négligeable (moins de 0.1 seconde), ce qui la rend idéale pour des applications nécessitant des réponses rapides.

\subsection{Validation sur Grande Instance (439.in)}

Le test complémentaire sur l'instance 439.in (439 villes) a permis de valider la robustesse des algorithmes face à des problèmes de taille réelle :

\begin{itemize}
    \item \textbf{Branch and Bound} : Timeout (600s) - confirme que l'algorithme exact est inexploitable au-delà de 20-25 villes, même avec un timeout étendu.
    
    \item \textbf{Heuristique constructive} : Maintient sa rapidité exceptionnelle (0.05s) et sa complexité $\mathcal{O}(n^2)$ reste parfaitement gérable même sur de très grandes instances.
    
    \item \textbf{LocalSearch (2-opt)} : Se révèle être le \textbf{seul algorithme d'amélioration viable} sur cette grande instance. En 292 secondes (~5 minutes), il produit une solution 13.8\% meilleure que la solution constructive (113\,210 vs 131\,281), soit un gain de 18\,071 unités de distance.
    
    \item \textbf{GRASP} : Timeout (600s) - révèle une limite de scalabilité avec 100 itérations. Pour des instances de cette taille, une adaptation des paramètres est nécessaire (réduction à 10-20 itérations).
\end{itemize}

\textbf{Conclusion du test 439.in :} Ce test confirme que \textbf{LocalSearch est l'algorithme le plus robuste} sur l'ensemble du spectre de tailles d'instances, offrant un excellent compromis qualité/temps même sur de très grandes instances.

\subsection{Recommandations Pratiques}

En fonction du contexte d'utilisation, nous recommandons :

\begin{itemize}
    \item \textbf{Instances très petites ($n < 20$)} : Utiliser Branch and Bound pour garantir l'optimalité
    \item \textbf{Instances moyennes ($20 \le n \le 100$)} : Utiliser LocalSearch pour un résultat rapide et relativement précis, ou GRASP pour la meilleure qualité
    \item \textbf{Grandes instances ($n > 100$)} : Utiliser LocalSearch (robuste et efficace) ou GRASP avec un nombre d'itérations adapté
    \item \textbf{Applications temps réel} : Utiliser LocalSearch pour sa rapidité
\end{itemize}



\end{document}
