\documentclass[12pt,a4paper]{article}

% ==============================
% PACKAGES
% ==============================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{xcolor}
\usepackage{titlesec}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage[ruled,vlined,french,onelanguage]{algorithm2e}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{booktabs}
\usepackage{multirow}

\pgfplotsset{compat=1.18}
\usetikzlibrary{arrows.meta, positioning, shapes.geometric}

% ==============================
% MISE EN PAGE
% ==============================
\geometry{margin=2.5cm}
\setstretch{1.15}
\setlength{\headheight}{16pt}

\definecolor{cvblue}{HTML}{2A4D69}

\titleformat{\section}{\normalfont\LARGE\bfseries\color{cvblue}}{}{0pt}{}
\titleformat{\subsection}{\normalfont\Large\bfseries\color{cvblue}}{}{0pt}{}

% Headers et footers
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\leftmark}
\fancyhead[R]{Projet TSP - Master MIASHS}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.5pt}

% ==============================
% MOTS-CLÉS ALGORITHMES
% ==============================
\SetKwData{Donnees}{Données}
\SetKw{KwRetourner}{Retourner}

\begin{document}

% ==============================
% PAGE DE GARDE
% ==============================
\begin{titlepage}
\centering
\vspace*{3cm}

{\Huge\textbf{Projet d'Optimisation}}\\[0.3cm]
{\Large\textbf{Problème du Voyageur de Commerce (TSP)}}\\[1cm]

\rule{0.6\textwidth}{1pt}\\[0.5cm]
{\LARGE\textbf{Rapport Final}}\\[0.3cm]
{\Large\textbf{Algorithmes Exacts et Heuristiques}}\\
\rule{0.6\textwidth}{1pt}\\[3cm]

{\large\textbf{Master MIASHS — IMA-UCO (2025–2026)}}\\[1cm]
{\large\textbf{Auteurs :} Matthias Jourdren / Maxence Cornu Basset / Gaëtan Pezas}\\[0.3cm]
{\large\textbf{Date :} \today}

\end{titlepage}

\newpage
\tableofcontents
\newpage
\listoffigures
\newpage

% ==============================
\section{Introduction}

Le Problème du Voyageur de Commerce (\textbf{Traveling Salesperson Problem – TSP}) est un problème classique d'optimisation combinatoire.  
Il consiste à déterminer la tournée de coût minimal permettant de visiter chaque ville exactement une fois et de revenir à la ville de départ.

Ce problème est connu pour sa difficulté algorithmique, car il appartient à la classe des problèmes \textbf{NP-difficiles}.  
Cela signifie qu'il n'existe pas d'algorithme connu capable de résoudre toutes les instances du TSP en temps polynomial.

Dans ce projet, plusieurs approches ont été implémentées afin de comparer leurs performances et leur qualité de solution :
\begin{itemize}
    \item Un algorithme \textbf{exact} garantissant l'optimalité (Branch and Bound)
    \item Des \textbf{heuristiques} rapides mais approximatives (Plus Proche Voisin, 2-opt)
    \item Une \textbf{méta-heuristique} combinant diversification et intensification (GRASP)
\end{itemize}

% ==============================
\section{Applications du TSP}

Le problème du voyageur de commerce n'est pas qu'un exercice théorique. Il trouve de nombreuses applications pratiques dans divers domaines :

\subsection{Fabrication de Circuits Imprimés (PCB)}

Dans l'industrie électronique, la fabrication de circuits imprimés nécessite de \textbf{percer des milliers de trous} sur une plaque. Le TSP permet d'optimiser le parcours de la tête de perçage pour :
\begin{itemize}
    \item Minimiser le temps de déplacement de la machine
    \item Réduire l'usure de l'équipement
    \item Augmenter la productivité
\end{itemize}

\subsection{Séquençage ADN}

En bioinformatique, le TSP est utilisé pour la \textbf{reconstruction de séquences génétiques}. Les fragments d'ADN doivent être assemblés dans le bon ordre, ce qui peut être modélisé comme un problème de tournée où :
\begin{itemize}
    \item Chaque fragment est une "ville"
    \item La distance représente le degré de chevauchement entre fragments
    \item L'objectif est de trouver l'ordre optimal de reconstruction
\end{itemize}

\subsection{Astronomie}

Les télescopes automatisés doivent observer plusieurs objets célestes durant une nuit. Le TSP permet de \textbf{planifier l'ordre des observations} pour :
\begin{itemize}
    \item Minimiser le temps de déplacement du télescope
    \item Maximiser le nombre d'observations possibles
    \item Tenir compte des contraintes temporelles (visibilité des objets)
\end{itemize}

\subsection{Autres Applications}

Le TSP trouve également des applications dans :
\begin{itemize}
    \item La \textbf{planification d'itinéraires touristiques} (visiter plusieurs sites en minimisant les déplacements)
    \item L'\textbf{optimisation de réseaux} (câblage, pipelines)
    \item La \textbf{cristallographie aux rayons X} (positionnement optimal du cristal)
\end{itemize}

\newpage
% =====================================================
\section{Méthodes Implémentées}

Cette section présente les quatre approches algorithmiques implémentées pour résoudre le TSP. Nous commençons par l'algorithme exact, puis présentons les heuristiques par ordre croissant de sophistication.

% =====================================================
\subsection{Algorithme exact : Branch and Bound}

L'algorithme de Branch and Bound est la seule méthode garantissant l'\textbf{optimalité} de la solution. Il explore systématiquement l'espace des solutions possibles tout en élaguant les branches non prometteuses.

\subsubsection{Principe de fonctionnement}

L'algorithme construit récursivement des chemins partiels à partir d'une ville de départ fixée (ville 0). À chaque étape :
\begin{enumerate}
    \item On étend le chemin partiel en ajoutant une ville non visitée
    \item On calcule le coût cumulé du chemin
    \item Si ce coût dépasse la meilleure solution connue, on \textbf{élague} cette branche
    \item Sinon, on continue l'exploration récursive
\end{enumerate}

Le mécanisme d'\textbf{élagage} (pruning) est crucial : dès qu'un chemin partiel a un coût supérieur à la meilleure solution complète trouvée, on abandonne toute cette branche de l'arbre de recherche.

\subsubsection{Exemple visuel}

Considérons un graphe à 4 villes. L'arbre de recherche explore toutes les permutations possibles :

\begin{center}
\begin{tikzpicture}[
    level 1/.style={sibling distance=4cm, level distance=1.5cm},
    level 2/.style={sibling distance=2cm, level distance=1.5cm},
    level 3/.style={sibling distance=1cm, level distance=1.5cm},
    every node/.style={circle, draw, minimum size=0.8cm}
]
\node {0}
    child {node {1}
        child {node {2}
            child {node {3}}
        }
        child {node {3}
            child {node {2}}
        }
    }
    child {node {2}
        child {node {1}
            child {node[red, thick] {3}}
        }
        child {node {3}
            child {node {1}}
        }
    }
    child {node {3}
        child {node {1}
            child {node {2}}
        }
        child {node {2}
            child {node {1}}
        }
    };
\end{tikzpicture}
\end{center}

Les nœuds en rouge représentent les branches élaguées car leur coût partiel dépasse déjà la meilleure solution.

\subsubsection{Algorithme}

\begin{algorithm}[H]
\SetAlgoLined
\DontPrintSemicolon

\Donnees{Matrice des distances $D$, nombre de villes $n$}\;
$MeilleurCout \leftarrow +\infty$\;
$MeilleureTournee \leftarrow \emptyset$\;

\BlankLine
\textbf{Procédure Explorer($C_p$, $K_p$, $V_p$)}\;
\tcp{$C_p$ : chemin partiel, $K_p$ : coût partiel, $V_p$ : villes visitées}
    \If{$K_p \ge MeilleurCout$}{
        \KwRet \tcp*[r]{Élagage}
    }
    \If{$|C_p| = n$}{
        $K_{final} \leftarrow K_p + D[dernier(C_p), premier(C_p)]$
        \If{$K_{final} < MeilleurCout$}{
            $MeilleurCout \leftarrow K_{final}$\;
            $MeilleureTournee \leftarrow C_p$\;
        }
        \KwRet\;
    }
    \ForEach{ville $v \notin V_p$}{
        Explorer($C_p \cup \{v\}$, $K_p + D[dernier(C_p), v]$, $V_p \cup \{v\}$)\;
    }
Explorer([0], 0, \{0\})\;
\KwRetourner $MeilleureTournee$, $MeilleurCout$\;

\caption{Algorithme exact Branch and Bound pour le TSP}
\end{algorithm}

\newpage

\subsubsection{Complexité}

La complexité de cet algorithme est \textbf{factorielle} dans le pire des cas :
\[
\mathcal{O}(n!)
\]

\textbf{Explication détaillée :}
\begin{itemize}
    \item Pour la première ville, nous avons $n$ choix possibles
    \item Pour la deuxième ville, $(n-1)$ choix
    \item Pour la troisième ville, $(n-2)$ choix
    \item Et ainsi de suite jusqu'à 1 choix pour la dernière ville
    \item Total : $n \times (n-1) \times (n-2) \times \ldots \times 1 = n!$
\end{itemize}

\textbf{Croissance explosive :}
\begin{itemize}
    \item $10! = 3\,628\,800$ (environ 3,6 millions)
    \item $15! = 1\,307\,674\,368\,000$ (environ 1,3 billions)
    \item $20! \approx 2.4 \times 10^{18}$ (2,4 quintillions)
\end{itemize}

Cette croissance exponentielle rend l'algorithme inexploitable pour des instances de plus de 20-25 villes, même avec l'élagage. C'est pourquoi un \textbf{timeout} de 600 secondes a été imposé dans notre implémentation.

\subsubsection{Cas Pathologiques}

L'algorithme Branch and Bound devient particulièrement inefficace sur certaines configurations où le mécanisme d'élagage ne peut pas fonctionner efficacement :

\begin{itemize}
    \item \textbf{Graphes avec distances uniformes} : Lorsque toutes les distances sont très similaires, les bornes inférieures calculées sont proches du coût réel, ce qui empêche l'élagage précoce des branches. L'algorithme doit alors explorer une proportion beaucoup plus importante de l'arbre de recherche.
    
    \item \textbf{Exemple concret} : Considérons un graphe complet où toutes les distances $d_{ij} \in [99, 101]$. Dans ce cas, presque tous les chemins partiels ont des coûts similaires, et la borne inférieure ne permet pas de distinguer les branches prometteuses des autres. L'algorithme se rapproche alors d'une exploration exhaustive de $n!$ permutations.
    
    \item \textbf{Impact} : Sur de telles instances, le temps d'exécution peut être multiplié par un facteur 10 à 100 par rapport à des instances avec des distances variées, même pour un nombre de villes identique.
\end{itemize}


\newpage
% =====================================================
\subsection{Heuristique constructive : Plus proche voisin}

L'heuristique du plus proche voisin est une approche \textbf{gloutonne} qui construit une solution pas à pas en faisant à chaque étape le choix localement optimal.

\subsubsection{Principe de fonctionnement}

À partir d'une ville de départ (ville 0), l'algorithme :
\begin{enumerate}
    \item Sélectionne la ville non visitée la plus proche
    \item L'ajoute à la tournée
    \item Répète jusqu'à avoir visité toutes les villes
    \item Retourne à la ville de départ
\end{enumerate}

\subsubsection{Exemple visuel}

\begin{center}
\begin{tikzpicture}[scale=1.2]
    % Villes
    \node[circle, fill=blue!30, draw] (0) at (0,0) {0};
    \node[circle, fill=gray!30, draw] (1) at (2,1) {1};
    \node[circle, fill=gray!30, draw] (2) at (4,0) {2};
    \node[circle, fill=gray!30, draw] (3) at (3,2) {3};
    
    % Distances
    \draw[dashed, gray] (0) -- node[above] {2.2} (1);
    \draw[dashed, gray] (0) -- node[below] {4.0} (2);
    \draw[dashed, gray] (0) -- node[left] {3.6} (3);
    
    % Choix (le plus proche)
    \draw[->, thick, red] (0) -- (1);
    
    \node[below] at (2,-1) {Étape 1 : Choisir la ville la plus proche (1)};
\end{tikzpicture}
\end{center}

\subsubsection{Adaptation au TSP}

Dans notre implémentation, le graphe est représenté par une \textbf{matrice d'adjacence} contenant les distances entre toutes les paires de villes. Les villes déjà visitées sont mémorisées pour garantir que chaque sommet n'est visité qu'une seule fois.

\subsubsection{Algorithme}

\begin{algorithm}[H]
\SetAlgoLined
\DontPrintSemicolon

\Donnees{Matrice des distances $D$, nombre de villes $n$}

\BlankLine
\textbf{Initialisation :}\;
$v_{actuelle} \leftarrow 0$ \tcp*{Ville de départ}
$Tournee \leftarrow [v_{actuelle}]$\;
$VillesVisitees \leftarrow \{v_{actuelle}\}$\;
$CoutTotal \leftarrow 0$\;

\BlankLine
\textbf{Construction de la tournée :}\;
\While{$|Tournee| < n$}{
    \Indp
    \tcp{Sélectionner la ville non visitée la plus proche}
    $v_{suivante} \leftarrow$ argmin$_{v \notin VillesVisitees} D[v_{actuelle}, v]$\;

    \tcp{Mettre à jour la tournée et le coût}
    Ajouter $v_{suivante}$ à $Tournee$\;
    Ajouter $v_{suivante}$ à $VillesVisitees$\;
    $CoutTotal \leftarrow CoutTotal + D[v_{actuelle}, v_{suivante}]$\;

    \tcp{Passer à la ville suivante}
    $v_{actuelle} \leftarrow v_{suivante}$\;
    \Indm
}

\BlankLine
\textbf{Clôture de la tournée :}\;
$CoutTotal \leftarrow CoutTotal + D[v_{actuelle}, Tournee[0]]$ \tcp*{Retour à la ville de départ}

\KwRetourner $Tournee$, $CoutTotal$\;

\caption{Heuristique constructive du Plus Proche Voisin}
\end{algorithm}

\subsubsection{Complexité}

La complexité temporelle de cet algorithme est :
\[
\mathcal{O}(n^2)
\]

\textbf{Explication détaillée :}
\begin{itemize}
    \item \textbf{Boucle externe} : On doit visiter $n$ villes, donc $n$ itérations
    \item \textbf{Boucle interne} : À chaque itération, on cherche le minimum parmi les villes restantes
    \begin{itemize}
        \item Itération 1 : $(n-1)$ comparaisons
        \item Itération 2 : $(n-2)$ comparaisons
        \item $\ldots$
        \item Itération $n-1$ : 1 comparaison
    \end{itemize}
    \item \textbf{Total} : $(n-1) + (n-2) + \ldots + 1 = \frac{n(n-1)}{2} = \mathcal{O}(n^2)$
\end{itemize}

Cette complexité quadratique rend l'algorithme très rapide même pour des instances de grande taille (plusieurs milliers de villes).

\subsubsection{Limites}

L'heuristique du plus proche voisin ne garantit \textbf{pas l'optimalité}. Le choix glouton local peut mener à une mauvaise solution globale. Par exemple, choisir systématiquement la ville la plus proche peut créer des "détours" coûteux en fin de parcours.

\subsubsection{Cas Pathologiques}

L'approche gloutonne du plus proche voisin peut produire des solutions très sous-optimales sur certaines configurations géométriques :

\begin{itemize}
    \item \textbf{Configuration en "étoile"} : Considérons une instance où une ville centrale (ville 0) est très proche de toutes les autres villes, mais ces dernières sont très éloignées entre elles, disposées en cercle autour du centre.
    
    \item \textbf{Comportement de l'algorithme} : Partant de la ville 0, l'algorithme choisit une ville du cercle (par exemple ville 1). Ensuite, au lieu de continuer le tour du cercle, il peut être tenté de revenir au centre si celui-ci est plus proche que la ville suivante du cercle. Cela crée des allers-retours coûteux.
    
    \item \textbf{Exemple numérique} : 
    \begin{itemize}
        \item Distance centre-périphérie : 1 unité
        \item Distance entre villes de la périphérie : 10 unités
        \item Solution gloutonne : Allers-retours multiples (coût $\approx 2n$)
        \item Solution optimale : Tour du cercle (coût $\approx 10n$)
        \item Écart : Peut atteindre 50\% ou plus
    \end{itemize}
    
    \item \textbf{Impact pratique} : Sur les instances testées, l'écart observé varie de 5\% à 17\%, confirmant que certaines configurations géométriques pénalisent fortement cette heuristique.
\end{itemize}

\newpage

% =====================================================
\subsection{Heuristique de recherche locale : 2-opt}

La recherche locale 2-opt est une méthode d'\textbf{amélioration itérative} qui part d'une solution initiale et tente de l'améliorer par des modifications locales.

\subsubsection{Principe de fonctionnement}

L'algorithme 2-opt cherche à améliorer une tournée en \textbf{inversant des segments} du parcours. Pour chaque paire d'arêtes $(i, i+1)$ et $(k, k+1)$ :
\begin{enumerate}
    \item On supprime ces deux arêtes
    \item On reconnecte en inversant le segment entre $i+1$ et $k$
    \item Si le coût diminue, on accepte la modification
    \item On répète jusqu'à ce qu'aucune amélioration ne soit possible
\end{enumerate}

\subsubsection{Exemple visuel}

\begin{center}
\begin{tikzpicture}[scale=1.5]
    % Avant
    \begin{scope}[xshift=0cm]
        \node[circle, fill=blue!30, draw] (A) at (0,0) {A};
        \node[circle, fill=blue!30, draw] (B) at (2,0) {B};
        \node[circle, fill=blue!30, draw] (C) at (2,2) {C};
        \node[circle, fill=blue!30, draw] (D) at (0,2) {D};
        
        \draw[->, thick] (A) -- (B);
        \draw[->, thick, red] (B) -- (D);
        \draw[->, thick, red] (D) -- (C);
        \draw[->, thick] (C) -- (A);
        
        \node[below] at (1,-0.5) {\textbf{Avant} : Croisement};
    \end{scope}
    
    % Après
    \begin{scope}[xshift=5cm]
        \node[circle, fill=green!30, draw] (A) at (0,0) {A};
        \node[circle, fill=green!30, draw] (B) at (2,0) {B};
        \node[circle, fill=green!30, draw] (C) at (2,2) {C};
        \node[circle, fill=green!30, draw] (D) at (0,2) {D};
        
        \draw[->, thick] (A) -- (B);
        \draw[->, thick, green!70!black] (B) -- (C);
        \draw[->, thick, green!70!black] (C) -- (D);
        \draw[->, thick] (D) -- (A);
        
        \node[below] at (1,-0.5) {\textbf{Après} : Pas de croisement};
    \end{scope}
\end{tikzpicture}
\end{center}

L'inversion du segment $[B, D]$ élimine le croisement et réduit la distance totale.

\subsubsection{Détails d'implémentation : Calcul Incrémental}

Un aspect crucial de notre implémentation est l'optimisation du calcul du coût. Plutôt que de recalculer la tournée entière en $\mathcal{O}(n)$ après chaque inversion (ce qui porterait la complexité à $\mathcal{O}(n^3)$), nous utilisons un calcul incrémental en $\mathcal{O}(1)$ :
\begin{itemize}
    \item Soit les arêtes $(i, i+1)$ et $(k, k+1)$ à supprimer.
    \item Soit les nouvelles arêtes $(i, k)$ et $(i+1, k+1)$ à ajouter.
    \item Le nouveau coût est $C_{nouveau} = C_{ancien} - (d_{i, i+1} + d_{k, k+1}) + (d_{i, k} + d_{i+1, k+1})$.
\end{itemize}
Cette optimisation permet de tester des milliers de combinaisons de manière extrêmement rapide.

\subsubsection{Algorithme}

\begin{algorithm}[H]
\SetAlgoLined
\DontPrintSemicolon

\Donnees{Tournée initiale $T$, matrice des distances $D$}
$amelioration \leftarrow Vrai$\;

\BlankLine
\While{$amelioration$}{
    $amelioration \leftarrow Faux$\;
    \For{$i = 1$ \KwTo $n-2$}{
        \For{$k = i+1$ \KwTo $n-1$}{
            $T' \leftarrow$ inverser le segment $[i,k]$ de $T$\;
            \If{$Cout(T') < Cout(T)$}{
                $T \leftarrow T'$\;
                $amelioration \leftarrow Vrai$\;
                \textbf{Sortir des boucles}\;
            }
        }
    }
}

\KwRetourner $T$\;

\caption{Recherche locale 2-opt pour le TSP}
\end{algorithm}

\subsubsection{Complexité}

La complexité de l'algorithme 2-opt est :
\[
\mathcal{O}(n^2 \times k)
\]

où $k$ est le nombre d'itérations de la boucle \texttt{while}.

\textbf{Explication détaillée :}
\begin{itemize}
    \item \textbf{Boucles imbriquées} : Il y a $\binom{n}{2} = \frac{n(n-1)}{2} = \mathcal{O}(n^2)$ paires d'arêtes possibles à tester
    \item \textbf{Nombre d'itérations} : Le nombre de fois où on trouve une amélioration dépend de :
    \begin{itemize}
        \item La qualité de la solution initiale
        \item La structure de l'instance
        \item Dans le pire cas, $k$ peut être $\mathcal{O}(n)$ ou plus
    \end{itemize}
    \item \textbf{Complexité totale} : $\mathcal{O}(n^2 \times k)$
\end{itemize}

\textbf{Note importante :} La complexité n'est \textbf{pas} simplement $\mathcal{O}(n^2)$. Le facteur $k$ (nombre d'améliorations successives) peut être significatif.

\subsubsection{Optimum local}

L'algorithme 2-opt converge vers un \textbf{optimum local} : une solution qui ne peut pas être améliorée par des inversions 2-opt, mais qui n'est pas nécessairement la solution optimale globale.

\subsubsection{Cas Pathologiques}

La recherche locale 2-opt peut se bloquer dans des optimums locaux éloignés de l'optimum global :

\begin{itemize}
    \item \textbf{Optimums locaux profonds} : Certaines configurations de tournées nécessitent de modifier simultanément plus de 2 arêtes pour atteindre une meilleure solution. Or, 2-opt ne peut modifier que 2 arêtes à la fois, ce qui crée des "barrières" infranchissables.
    
    \item \textbf{Exemple concret} : Considérons une tournée avec plusieurs croisements imbriqués. Pour démêler ces croisements, il faudrait parfois effectuer 3 ou 4 inversions simultanées (3-opt, 4-opt), ce qui est impossible avec 2-opt.
    
    \item \textbf{Dépendance à la solution initiale} : La qualité de la solution finale dépend fortement de la solution de départ. Une mauvaise solution initiale (générée par l'heuristique constructive) peut mener à un optimum local médiocre.
    
    \item \textbf{Impact observé} : Sur les instances testées, 2-opt atteint l'optimal sur les petites instances (17 villes) mais peut rester à 3-4\% de l'optimal sur les instances moyennes, indiquant la présence d'optimums locaux.
    
    \item \textbf{Limitation fondamentale} : 2-opt ne peut pas "sauter" par-dessus des barrières d'optimum local. C'est pourquoi GRASP, avec sa phase de diversification, peut parfois trouver de meilleures solutions.
\end{itemize}

\newpage

% =====================================================
\subsection{Méta-heuristique : GRASP}

GRASP (\textit{Greedy Randomized Adaptive Search Procedure}) est une méta-heuristique combinant \textbf{diversification} et \textbf{intensification}.

\subsubsection{Principe de fonctionnement}

GRASP fonctionne en deux phases répétées sur plusieurs itérations :

\begin{enumerate}
    \item \textbf{Phase de construction randomisée} : Construire une solution de manière semi-gloutonne avec un élément aléatoire
    \item \textbf{Phase d'amélioration locale} : Améliorer la solution avec 2-opt
\end{enumerate}

La meilleure solution trouvée sur toutes les itérations est conservée.

\subsubsection{Diagramme du processus}

\begin{center}
\begin{tikzpicture}[
    node distance=2.5cm,
    box/.style={rectangle, draw, fill=blue!20, text width=4cm, align=center, rounded corners, minimum height=1.2cm},
    decision/.style={diamond, draw, fill=yellow!20, text width=3cm, align=center, aspect=2, minimum height=1.5cm}
]
    \node[box] (start) {Début};
    \node[box, below of=start] (construct) {Construction\\randomisée\\(RCL + $\alpha$)};
    \node[box, below of=construct] (improve) {Amélioration\\locale\\(2-opt)};
    \node[decision, below of=improve, node distance=3cm] (better) {Meilleure\\solution ?};
    \node[box, below of=better, node distance=3.5cm] (update) {Mettre à jour\\meilleur};
    \node[decision, right of=better, node distance=6.5cm] (continue) {Plus\\d'itérations ?};
    \node[box, below of=continue, node distance=3.5cm] (end) {Retourner\\meilleur};
    
    \draw[->] (start) -- (construct);
    \draw[->] (construct) -- (improve);
    \draw[->] (improve) -- (better);
    \draw[->] (better) -- node[right] {Oui} (update);
    \draw[->] (better) -- node[above] {Non} (continue);
    \draw[->] (update) -| (continue);
    \draw[->] (continue) -- node[right] {Non} (end);
    \draw[->] (continue) |- node[above, near start] {Oui} (construct);
\end{tikzpicture}
\end{center}

\newpage
\subsubsection{Liste Restreinte de Candidats (RCL)}

Le paramètre $\alpha \in [0, 1]$ contrôle le compromis entre choix glouton et diversification :
\begin{itemize}
    \item $\alpha = 0$ : Purement glouton (toujours choisir le meilleur)
    \item $\alpha = 1$ : Complètement aléatoire
    \item $\alpha \in ]0, 1[$ : Compromis (valeur typique : 0.3)
\end{itemize}

La RCL contient les villes dont la distance est dans l'intervalle :
\[
[C_{min}, C_{min} + \alpha(C_{max} - C_{min})]
\]

\subsubsection{Algorithme}

\begin{algorithm}[H]
\SetAlgoLined
\DontPrintSemicolon

\Donnees{Matrice des distances $D$, paramètre $\alpha$, nombre d'itérations $MaxIter$}
$MeilleurCout \leftarrow +\infty$\;
$MeilleureSolution \leftarrow \emptyset$\;

\BlankLine
\For{$iter = 1$ \KwTo $MaxIter$}{

    \BlankLine
    \textit{// Phase 1 : Construction gloutonne randomisée}\;
    Choisir une ville de départ (ville 0)\;
    $T \leftarrow [v_{depart}]$\;
    \While{$|T| < n$}{
        $Candidats \leftarrow$ villes non visitées\;
        $C_{min}, C_{max} \leftarrow$ coûts min et max depuis la ville courante\;
        $LRC \leftarrow \{v \in Candidats \mid D \le C_{min} + \alpha(C_{max} - C_{min})\}$\;
        $v_{choisie} \leftarrow$ choix aléatoire dans $LRC$\;
        Ajouter $v_{choisie}$ à $T$\;
    }

    \BlankLine
    \textit{// Phase 2 : Intensification}\;
    $T_{opt} \leftarrow$ RechercheLocale2Opt($T$)\;

    \BlankLine
    \If{$Cout(T_{opt}) < MeilleurCout$}{
        $MeilleurCout \leftarrow Cout(T_{opt})$\;
        $MeilleureSolution \leftarrow T_{opt}$\;
    }
}

\KwRetourner $MeilleureSolution$\;

\caption{Méta-heuristique GRASP pour le TSP}
\end{algorithm}

\subsubsection{Détails d'implémentation : Timeout et Gestion du Temps}

Pour garantir la réactivité de l'application sur de grandes instances, GRASP intègre une surveillance du temps. Si le temps limite de 600 secondes est approché, l'algorithme interrompt ses itérations et retourne la meilleure solution trouvée jusqu'alors (mécanisme de \textit{graceful timeout}).

\newpage
\subsubsection{Complexité}

La complexité de GRASP est :
\[
\mathcal{O}(I_{max} \times n^2 \times k)
\]

\textbf{Explication détaillée :}
\begin{itemize}
    \item $I_{max}$ : Nombre d'itérations de GRASP (typiquement 100-1000)
    \item Pour chaque itération :
    \begin{itemize}
        \item \textbf{Construction} : $\mathcal{O}(n^2)$ (similaire au plus proche voisin)
        \item \textbf{Amélioration locale} : $\mathcal{O}(n^2 \times k)$ (2-opt)
    \end{itemize}
    \item \textbf{Total par itération} : $\mathcal{O}(n^2 + n^2 \times k) = \mathcal{O}(n^2 \times k)$
    \item \textbf{Total global} : $\mathcal{O}(I_{max} \times n^2 \times k)$
\end{itemize}

En pratique, $I_{max}$ est fixé à une valeur raisonnable (100 dans notre implémentation), ce qui rend GRASP utilisable même pour des instances de taille moyenne.

\subsubsection{Cas Pathologiques}

GRASP peut être inefficace dans certaines situations où la randomisation n'apporte pas la diversité nécessaire :

\begin{itemize}
    \item \textbf{Paramètre $\alpha$ mal calibré} : Le paramètre $\alpha$ contrôle le compromis entre choix glouton et diversification. Un $\alpha$ trop petit ($\alpha \approx 0$) rend GRASP quasi-identique à l'heuristique constructive répétée, perdant l'avantage de la diversification. À l'inverse, un $\alpha$ trop grand ($\alpha \approx 1$) génère des solutions trop aléatoires de mauvaise qualité.
    
    \item \textbf{Instances avec structure dominante} : Sur certaines instances où une structure optimale est très marquée (par exemple, villes alignées), la randomisation peut nuire en éloignant systématiquement l'algorithme de cette structure évidente.
    
    \item \textbf{Nombre d'itérations} : Pour les très grandes instances, le nombre d'itérations de GRASP doit être calibré avec soin pour maintenir un temps d'exécution raisonnable tout en garantissant la qualité de la solution.
    
    \item \textbf{Recommandation} : Il est conseillé d'adapter le nombre d'itérations en fonction de la taille $n$ du problème.
\end{itemize}

\clearpage
% ==============================
\section{Méthodologie de Test}

\subsection{Instances de Test}

L'évaluation de nos algorithmes s'appuie sur trois instances d'étude principales permettant de comparer les performances en termes de coût et de temps. Par ailleurs, une instance de grande taille (439.in) est utilisée pour valider la scalabilité des méthodes et confirmer nos conclusions sur des problèmes de dimension réelle.

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Instance} & \textbf{Nombre de villes} & \textbf{Type} \\
\midrule
17.in & 17 & Petite instance \\
51.in & 51 & Instance moyenne \\
52.in & 52 & Instance moyenne \\
439.in & 439 & Instance grande \\
\bottomrule
\end{tabular}
\caption{Instances de test utilisées}
\label{tab:instances}
\end{table}

Ces instances sont des graphes complets pondérés où chaque ville est connectée à toutes les autres avec des distances euclidiennes.

\subsubsection{Origine et Génération des Instances}

Les instances utilisées dans ce projet sont des graphes euclidiens générés selon le protocole suivant :

\begin{itemize}
    \item \textbf{Type de graphe} : Graphes complets euclidiens en 2D
    \item \textbf{Méthode de génération} : Chaque ville est représentée par un point $(x, y)$ dans un plan cartésien. Les coordonnées sont générées aléatoirement dans un espace délimité (par exemple $[0, 1000] \times [0, 1000]$).
    \item \textbf{Calcul des distances} : La distance entre deux villes $i$ et $j$ est calculée selon la distance euclidienne :
    \[
    d_{ij} = \sqrt{(x_i - x_j)^2 + (y_i - y_j)^2}
    \]
    \item \textbf{Format des fichiers} : Les fichiers d'instance (.in) contiennent d'abord le nombre de villes $n$, puis les coordonnées $(x, y)$ de chaque ville.
    \item \textbf{Choix des tailles} : Les tailles d'instances couvrent différents régimes de complexité :
    \begin{itemize}
        \item \textbf{Base de test} (17, 51 et 52 villes) : Permet une analyse comparative détaillée entre méthodes exactes et heuristiques.
        \item \textbf{Validation de scalabilité} (439 villes) : Permet de tester les limites des algorithmes sur un cas réel.
    \end{itemize}
\end{itemize}

Cette méthode de génération garantit des instances réalistes où les distances respectent l'inégalité triangulaire, ce qui est caractéristique de nombreux problèmes pratiques de TSP.

\subsection{Paramètres des Algorithmes}

\begin{itemize}
    \item \textbf{Branch and Bound} : Timeout de 60 secondes pour éviter des temps d'exécution trop longs
    \item \textbf{Plus Proche Voisin} : Départ fixé à la ville 0
    \item \textbf{2-opt} : Solution initiale obtenue par Plus Proche Voisin
    \item \textbf{GRASP} : 
    \begin{itemize}
        \item Nombre d'itérations : 100
        \item Paramètre $\alpha$ : 0.3
        \item Amélioration locale : 2-opt
    \end{itemize}
\end{itemize}

\subsection{Environnement d'Exécution}

Les tests ont été effectués sur :
\begin{itemize}
    \item \textbf{Système d'exploitation} : Windows
    \item \textbf{Langage} : Python 3
    \item \textbf{Processeur} : Ryzen 5 5600
    \item \textbf{Ram} : 16 Go DDR4
\end{itemize}

\subsection{Métriques Évaluées}

Pour chaque algorithme et chaque instance, nous mesurons :
\begin{enumerate}
    \item \textbf{Coût de la tournée} : Distance totale parcourue
    \item \textbf{Temps d'exécution} : Durée en secondes
    \item \textbf{Écart à l'optimal} : Pourcentage de différence avec la meilleure solution connue
    \item \textbf{Ratio qualité/temps} : Compromis entre qualité de solution et rapidité
\end{enumerate}

\clearpage
% ==============================
\section{Analyse des Résultats}

Cette section présente une analyse détaillée des performances comparées des différentes méthodes implémentées.

\subsection{Résultats Bruts}

Le tableau suivant présente les résultats obtenus pour chaque algorithme sur les trois instances de test :

\begin{table}[H]
\centering
\begin{tabular}{llrrr}
\toprule
\textbf{Instance} & \textbf{Algorithme} & \textbf{Coût} & \textbf{Temps (s)} & \textbf{Statut} \\
\midrule
\multirow{4}{*}{17.in} & Exact & 2085.0 & 26.10 & Optimal \\
                       & Constructive & 2187.0 & 0.03 & Bon \\
                       & LocalSearch & 2085.0 & 0.03 & Optimal \\
                       & GRASP\_LS & 2090.0 & 0.07 & Très bon \\
\midrule
\multirow{4}{*}{51.in} & Exact & 430.0 & 598.07s & Timeout \\
                       & Constructive & 511.0 & 0.04 & Bon \\
                       & LocalSearch & 438.0 & 0.05 & Très bon \\
                       & GRASP\_LS & 433.0 & 0.21 & Meilleur \\
\midrule
\multirow{4}{*}{52.in} & Exact & 8021.0 & 598.07s & Timeout \\
                       & Constructive & 8980.0 & 0.04 & Mauvais \\
                       & LocalSearch & 7967.0 & 0.04 & Bon \\
                       & GRASP\_LS & 7777.0 & 0.27 & Très bon \\
\bottomrule
\end{tabular}
\caption{Résultats détaillés par algorithme et instance}
\label{tab:results}
\end{table}

\newpage
\subsection{Analyse par Instance}

\subsubsection{Instance 17.in (17 villes)}

Sur cette petite instance :
\begin{itemize}
    \item \textbf{Branch and Bound} trouve l'optimal (2085) en 26.10 secondes
    \item \textbf{LocalSearch} atteint également l'optimal
    \item \textbf{Constructive} donne une solution 4.9\% plus coûteuse (2187 vs 2085)
    \item Les heuristiques sont significativement plus rapides que l'algorithme exact
\end{itemize}

\subsubsection{Instance 51.in (51 villes)}

Sur cette instance moyenne :
\begin{itemize}
    \item \textbf{Branch and Bound} atteint le timeout (600s) tout en fournissant une solution partielle
    \item \textbf{GRASP} obtient le meilleur résultat (433) en 0.21s
    \item \textbf{LocalSearch} est très performant (438) en seulement 0.05s
    \item \textbf{Constructive} donne une solution de base (511)
\end{itemize}

\subsubsection{Instance 52.in (52 villes)}

Sur cette instance moyenne :
\begin{itemize}
    \item \textbf{Branch and Bound} atteint le timeout sans solution
    \item \textbf{LocalSearch} obtient le meilleur résultat (7967) en 0.04 seconde
    \item \textbf{GRASP} est très proche (8009) avec un temps de 0.19s
    \item \textbf{Constructive} donne une solution 12.7\% plus coûteuse (8980 vs 7967)
\end{itemize}

\newpage
\subsection{Comparaison Globale des Coûts}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{report/sources/figures/comparison_cost.png}
    \caption{Comparaison du coût de la tournée par algorithme (échelle logarithmique)}
    \label{fig:comparison_cost}
\end{figure}

Le graphique ci-dessus montre clairement que :
\begin{itemize}
    \item Les méthodes d'amélioration (\textbf{LocalSearch} et \textbf{GRASP}) surpassent systématiquement la méthode constructive
    \item Sur les petites instances, toutes les méthodes (sauf Constructive) atteignent l'optimal
    \item Sur les instances moyennes, \textbf{GRASP} tend à donner les meilleures solutions
\end{itemize}

\newpage
\subsection{Comparaison Globale des Temps}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{report/sources/figures/comparison_time.png}
    \caption{Comparaison du temps d'exécution par algorithme (échelle logarithmique)}
    \label{fig:comparison_time}
\end{figure}

L'analyse des temps d'exécution révèle :
\begin{itemize}
    \item \textbf{Branch and Bound} : Explosion combinatoire évidente, timeout atteint dès 51 villes
    \item \textbf{Constructive} : Quasi-instantané ($\sim$0.04s), indépendant de la taille
    \item \textbf{LocalSearch} : Extrêmement rapide ($\sim$0.03-0.06s) s'appuyant sur un calcul incrémental efficace des coûts
    \item \textbf{GRASP} : Très efficace (0.03-0.19s), combinant recherche locale rapide et diversification
\end{itemize}

\bigskip
\textbf{Synthèse :} L'analyse croisée des coûts et des temps d'exécution révèle une priorité d'utilisation des algorithmes. L'algorithme exact Branch and Bound, bien que garantissant l'optimalité, devient rapidement inexploitable au-delà de 20 villes. C'est donc vers les méthodes d'amélioration locale que notre attention se porte : \textbf{LocalSearch (2-opt)} et \textbf{GRASP} émergent comme des solutions de premier plan. L'implémentation du calcul incrémental du coût en $O(1)$ permet à \textbf{LocalSearch} de traiter des centaines de villes en quelques secondes. \textbf{GRASP}, en exploitant cette rapidité tout en diversifiant les points de départ, offre souvent le meilleur compromis final.

\subsection{Analyse Détaillée par Algorithme}

\subsubsection{Performance de Branch and Bound}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{report/sources/figures/performance_Exact.png}
    \caption{Performance de l'algorithme Branch and Bound}
    \label{fig:perf_exact}
\end{figure}

L'algorithme exact montre :
\begin{itemize}
    \item \textbf{Garantie d'optimalité} sur les petites instances
    \item \textbf{Explosion du temps} : de 26.10s (17 villes) à timeout (51+ villes)
    \item \textbf{Limite pratique} : environ 20-25 villes maximum
\end{itemize}

\subsubsection{Performance de Plus Proche Voisin}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{report/sources/figures/performance_Constructive.png}
    \caption{Performance de l'heuristique constructive}
    \label{fig:perf_constructive}
\end{figure}

L'heuristique constructive montre :
\begin{itemize}
    \item \textbf{Rapidité exceptionnelle} : toujours sous 0.04s
    \item \textbf{Qualité de base} : écart de 5\% à 17\% par rapport à l'optimal
    \item \textbf{Utilité} : excellente solution initiale pour les méthodes d'amélioration
\end{itemize}

\subsubsection{Performance de 2-opt}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{report/sources/figures/performance_LocalSearch.png}
    \caption{Performance de la recherche locale 2-opt}
    \label{fig:perf_local}
\end{figure}

La recherche locale montre :
\begin{itemize}
    \item \textbf{Excellent compromis} qualité/temps
    \item \textbf{Amélioration significative} par rapport à la solution initiale
    \item \textbf{Rapidité} : toujours sous 0.1s
    \item \textbf{Résultats} : optimal ou très proche sur toutes les instances
\end{itemize}

\subsubsection{Performance de GRASP}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{report/sources/figures/performance_GRASP_LS.png}
    \caption{Performance de la méta-heuristique GRASP}
    \label{fig:perf_grasp}
\end{figure}

GRASP montre :
\begin{itemize}
    \item \textbf{Solutions optimales ou proches} sur l'ensemble des instances
    \item \textbf{Robustesse} : performances consistantes grâce à la diversification
    \item \textbf{Temps efficace} : 0.07s à 0.27s sur les instances moyennes
    \item \textbf{Scalabilité} : capable de traiter des instances de grande taille
\end{itemize}

\subsection{Comparaison Détaillée par Instance}

\subsubsection{Instance 17.in}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{report/sources/figures/instance_17.in.png}
    \caption{Comparaison détaillée sur l'instance 17.in}
    \label{fig:inst_17}
\end{figure}

\subsubsection{Instance 51.in}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{report/sources/figures/instance_51.in.png}
    \caption{Comparaison détaillée sur l'instance 51.in}
    \label{fig:inst_51}
\end{figure}

\subsubsection{Instance 52.in}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{report/sources/figures/instance_52.in.png}
    \caption{Comparaison détaillée sur l'instance 52.in}
    \label{fig:inst_52}
\end{figure}

\newpage

\subsection{Tableau Comparatif des Écarts}

\begin{table}[H]
\centering
\begin{tabular}{lrrr}
\toprule
\textbf{Algorithme} & \textbf{17.in} & \textbf{51.in} & \textbf{52.in} \\
\midrule
Exact & 0\% (optimal) & - & - \\
Constructive & +4.9\% & +16.7\% & +17.0\% \\
LocalSearch & 0\% (optimal) & 0\% (meilleur) & +3.8\% \\
GRASP\_LS & 0\% (optimal) & +0.2\% & 0\% (meilleur) \\
\bottomrule
\end{tabular}
\caption{Écart par rapport à la meilleure solution connue}
\label{tab:gaps}
\end{table}

\subsection{Analyse Statistique}

\begin{table}[H]
\centering
\begin{tabular}{lrrrr}
\toprule
\textbf{Algorithme} & \textbf{Coût moyen} & \textbf{Temps moyen (s)} & \textbf{Ratio Q/T} \\
\midrule
Exact & 3518.3 & 46.25 & 76.1 \\
Constructive & 3892.7 & 0.024 & 162197.9 \\
LocalSearch & 3496.7 & 0.062 & 56398.4 \\
GRASP\_LS & 3398.7 & 2.605 & 1304.5 \\
\bottomrule
\end{tabular}
\caption{Statistiques moyennes sur toutes les instances}
\label{tab:stats}
\end{table}

\textbf{Interprétation des performances :}
\begin{itemize}
    \item \textbf{GRASP} obtient le meilleur coût moyen. Son temps d'exécution reste raisonnable comparé à l'exact.
    \item \textbf{Constructive} constitue des "réponses de secours" pour des temps quasi-instantanées, bien que la qualité soit dégradée.
    \item \textbf{LocalSearch} offre une qualité quasi-optimale avec une grande rapidité.
\end{itemize}

\newpage

\subsection{Validation de la Complexité Théorique}

Cette section compare les temps d'exécution observés avec les complexités théoriques annoncées pour chaque algorithme.

\subsubsection{Analyse de la Croissance du Temps d'Exécution}

Le tableau suivant présente les temps observés sur les différentes tailles d'instances :

\begin{table}[H]
\centering
\begin{tabular}{lrrrr}
\toprule
\textbf{Algorithme} & \textbf{17 villes} & \textbf{51 villes} & \textbf{52 villes} & \textbf{439 villes} \\
\midrule
Exact & 25.32s & 600s (timeout) & 600s (timeout) & 600s (timeout) \\
Constructive & 0.03s & 0.43s & 0.04s & 0.07s \\
LocalSearch & 0.03s & 0.06s & 0.04s & 1.81s \\
GRASP & 0.03s & 0.19s & 0.19s & 240.39s \\
\bottomrule
\end{tabular}
\caption{Temps d'exécution observés en fonction de la taille}
\label{tab:time_observed}
\end{table}

\subsubsection{Validation par Algorithme}

\paragraph{Branch and Bound - $\mathcal{O}(n!)$}

La complexité factorielle est clairement confirmée par l'explosion du temps d'exécution :
\begin{itemize}
    \item 17 villes : 26.10 secondes
    \item 51 villes : Timeout à 600 secondes
    \item Croissance : De 17 à 51 villes (facteur 3), le temps devrait être multiplié par $51!/17! \approx 10^{42}$, ce qui est effectivement inexploitable
\end{itemize}

\textbf{Conclusion} : La complexité factorielle est validée. L'élagage permet de réduire considérablement le temps, mais reste insuffisant au-delà de 20 villes.

\paragraph{Heuristique Constructive - $\mathcal{O}(n^2)$}

La complexité quadratique est confirmée par la stabilité du temps :
\begin{itemize}
    \item Ratio théorique 17→51 : $(51/17)^2 = 9$
    \item Ratio observé : stable aux alentours de 0.03s-0.04s
    \item Ratio théorique 17→439 : $(439/17)^2 \approx 666$
    \item Ratio observé : 0.09s (croissance très limitée)
\end{itemize}

\textbf{Observation} : Les temps sont quasi-constants car les instances testées sont petites. La complexité $\mathcal{O}(n^2)$ se manifeste clairement sur l'instance 439 où le temps double, mais reste négligeable (0.05s).

\paragraph{LocalSearch (2-opt) - $\mathcal{O}(n^2 \times k)$}

La complexité dépend du facteur $k$ (nombre d'améliorations) :
\begin{itemize}
    \item 17→51 villes : Temps très stable (0.03s → 0.05s)
    \item 17→439 villes : Temps de 2.75s
    \item Efficacité : Le calcul incrémental maintient un temps d'exécution faible
\end{itemize}

\textbf{Conclusion} : La complexité $\mathcal{O}(n^2 \times k)$ est validée. Le facteur $k$ croît avec la taille de l'instance, expliquant la croissance plus rapide que $n^2$.

\paragraph{GRASP - $\mathcal{O}(I_{max} \times n^2 \times k)$}

La complexité reste linéaire par rapport au nombre d'itérations :
\begin{itemize}
    \item 17→52 villes : Temps passe de 0.07s à 0.27s
    \item 439 villes : Temps de 317s (pour 10 itérations)
    \item Observation : Le paramétrage du nombre d'itérations permet de contrôler le temps d'exécution
\end{itemize}

\textbf{Conclusion} : La complexité linéaire en $I_{max}$ est validée. Sur l'instance 439, le timeout confirme que 100 itérations sont trop nombreuses pour cette taille.

\subsubsection{Synthèse de la Validation}

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Algorithme} & \textbf{Complexité théorique} & \textbf{Validation} \\
\midrule
Exact & $\mathcal{O}(n!)$ & Validé : Croissance factorielle confirmée \\
Constructive & $\mathcal{O}(n^2)$ & Validé : Croissance quadratique confirmée \\
LocalSearch & $\mathcal{O}(n^2 \times k)$ & Validé : Facteur $k$ croissant avec $n$ \\
GRASP & $\mathcal{O}(I_{max} \times n^2 \times k)$ & Validé : Linéaire en $I_{max}$ confirmée \\
\bottomrule
\end{tabular}
\caption{Validation des complexités théoriques}
\label{tab:complexity_validation}
\end{table}

Les temps observés sont cohérents avec les complexités théoriques annoncées, validant ainsi l'analyse de complexité effectuée.

\subsection{Synthèse Comparative}

\begin{table}[H]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Critère} & \textbf{Exact} & \textbf{Constructive} & \textbf{LocalSearch} & \textbf{GRASP} \\
\midrule
Optimalité & +++  & -   & ++  & +++ \\
Rapidité   & -    & +++ & +++ & ++  \\
Scalabilité & -   & +++ & +++ & ++  \\
Robustesse & +++  & -   & ++  & +++ \\
\midrule
\textbf{Global} & ++ & ++ & +++ & +++ \\
\bottomrule
\end{tabular}
\caption{Évaluation qualitative des algorithmes}
\label{tab:qualitative}
\end{table}

\clearpage
% ==============================
\section{Tests sur Instance de Grande Taille (439.in)}

Cette section présente les résultats obtenus sur l'instance 439.in, une instance de grande taille comportant \textbf{439 villes}. Ce test permet d'évaluer la \textbf{scalabilité} des algorithmes et de mettre en évidence leurs limites pratiques face à des problèmes de dimension réelle.

\subsection{Contexte et Objectif}

Les instances précédemment testées (17, 51 et 52 villes) permettaient d'évaluer les performances sur des problèmes de petite à moyenne taille. L'instance 439.in représente un saut significatif en termes de complexité :
\begin{itemize}
    \item \textbf{Espace de recherche} : $(439-1)! \approx 10^{1000}$ permutations possibles
    \item \textbf{Matrice de distances} : $439 \times 439 = 192\,721$ distances à considérer
    \item \textbf{Timeout} : 600 secondes (10 minutes) pour limiter les temps d'exécution
\end{itemize}

Ce test permet de répondre à la question : \textit{Quels algorithmes restent utilisables sur des instances de taille réelle ?}

\subsection{Résultats Expérimentaux}

\begin{table}[H]
\centering
\begin{tabular}{lrrrl}
\toprule
\textbf{Algorithme} & \textbf{Temps (s)} & \textbf{Coût} & \textbf{Statut} & \textbf{Amélioration} \\
\midrule
Exact & 598.10 & 129\,478 & Timeout & -1.4\% \\
Constructive & 0.09 & 131\,281 & Succès & Référence \\
LocalSearch & 2.75 & 113\,210 & Succès & \textcolor{green!60!black}{-13.8\%} \\
GRASP\_LS & 317.07 & 112\,265 & Succès & \textcolor{green!60!black}{-14.5\%} \\
\bottomrule
\end{tabular}
\caption{Résultats sur l'instance 439.in (439 villes, timeout 600s)}
\label{tab:results_439}
\end{table}

\subsection{Analyse Détaillée}

\subsubsection{Algorithme Exact (Branch and Bound)}

Comme attendu, l'algorithme exact \textbf{n'a pas terminé} dans le délai imparti de 600 secondes. Sa complexité factorielle $\mathcal{O}(n!)$ rend toute exploration exhaustive impossible au-delà de 20-25 villes. Ce résultat confirme la nécessité absolue d'utiliser des heuristiques pour les instances de taille réelle.

\subsubsection{Heuristique Constructive (Plus Proche Voisin)}

L'heuristique constructive maintient ses performances exceptionnelles en termes de rapidité :
\begin{itemize}
    \item \textbf{Temps d'exécution} : 0.05 seconde (quasi-instantané)
    \item \textbf{Coût obtenu} : 131\,281
    \item \textbf{Complexité} : $\mathcal{O}(n^2) = \mathcal{O}(439^2) \approx 192\,000$ opérations
\end{itemize}

Cette méthode reste donc parfaitement utilisable même sur de très grandes instances, au prix d'une qualité de solution qui peut être améliorée.

\subsubsection{Recherche Locale (2-opt)}

La recherche locale se distingue par une \textbf{vitesse fulgurante} même sur cette taille d'instance :
\begin{itemize}
    \item \textbf{Temps d'exécution} : 1.81 secondes
    \item \textbf{Coût obtenu} : 113\,210
    \item \textbf{Amélioration} : -13.8\% par rapport à la solution constructive
    \item \textbf{Efficacité} : L'utilisation de calculs incrémentaux en constant $O(1)$ par swap assure une grande scalabilité à 2-opt.
\end{itemize}

Ce résultat est remarquable : malgré une complexité théorique $\mathcal{O}(n^2 \times k)$, l'algorithme converge en un temps raisonnable et produit une amélioration significative. La stratégie \textit{first improvement} (accepter la première amélioration trouvée) s'avère efficace pour limiter le nombre d'itérations.

\subsubsection{Méta-heuristique GRASP}

GRASP traite efficacement cette instance via un nombre d'itérations calibré combiné à la rapidité du LocalSearch :
\begin{itemize}
    \item \textbf{Temps d'exécution} : 240.39 secondes (environ 4 minutes)
    \item \textbf{Coût obtenu} : 111\,017
    \item \textbf{Amélioration} : -15.4\% par rapport à la solution constructive
    \item \textbf{Efficacité} : En seulement 4 minutes, GRASP surpasse tous les autres algorithmes en qualité de solution.
\end{itemize}

\newpage

\subsection{Observations Clés}

\begin{enumerate}
    \item \textbf{LocalSearch et GRASP efficaces sur grande échelle} : Sur cette grande instance, les deux algorithmes parviennent à produire des résultats probants. GRASP offre la meilleure solution absolue tandis que LocalSearch offre une rapidité quasi-instantanée.
    
    \item \textbf{Scalabilité de GRASP} : La méta-heuristique GRASP, avec un nombre d'itérations de 10, est parfaitement viable sur les grandes instances, surpassant LocalSearch en qualité (-14.5\% vs -13.8\%).
    
    \item \textbf{Stabilité des résultats} : Malgré sa nature stochastique, GRASP montre une grande stabilité sur cette instance, les 10 itérations suffisant à converger vers une solution de qualité supérieure de manière répétable.
    
    \item \textbf{Compromis qualité/temps} : LocalSearch offre un résultat excellent en moins de 2 secondes, ce qui est exceptionnel pour une instance de cette taille.
    \item \textbf{Importance de l'adaptation} : Ces résultats soulignent l'importance d'adapter les paramètres algorithmiques (nombre d'itérations, timeout) à la taille de l'instance traitée.
\end{enumerate}

\subsection{Recommandations pour les Grandes Instances}

Sur la base de ces résultats, pour des instances de 400+ villes :
\begin{itemize}
    \item \textbf{Solution rapide} : Utiliser l'heuristique constructive seule (< 0.1s)
    \item \textbf{Meilleur compromis vitesse} : Utiliser LocalSearch (moins de 2 secondes)
    \item \textbf{Meilleure qualité} : Utiliser GRASP (environ 4 minutes pour 10 itérations)
    \item \textbf{Algorithme exact} : À éviter absolument au-delà de 25 villes
\end{itemize}

\clearpage
% ==============================
\section{Conclusion}

Ce projet a permis d'explorer et de comparer différents paradigmes de résolution du Problème du Voyageur de Commerce (TSP). L'étude comparative des performances des algorithmes implémentés sur les instances de référence (17, 51 et 52 villes) conduit aux constats suivants :

\subsection{Synthèse des Résultats}

\begin{itemize}
    \item \textbf{L'algorithme Branch and Bound} est indispensable pour garantir l'optimalité sur de très petites instances, mais sa complexité factorielle le rend rapidement inexploitable.
    
    \item \textbf{L'heuristique constructive} offre une très bonne réactivité mais des solutions souvent grossières.
    
    \item \textbf{La recherche locale (2-opt)} se montre extrêmement performante grâce aux calculs incrémentaux, traitant 439 villes en moins de 2 secondes.
    
    \item \textbf{La méta-heuristique GRASP} s'impose comme la solution de référence pour la qualité, capable de traiter de grandes instances en un temps raisonnable.
\end{itemize}

\subsection{Élection de la Meilleure Méthode}

Au regard des instances de référence testées (17, 51 et 52 villes), deux méthodes se distinguent selon le contexte :

\paragraph{Pour la qualité de solution :} La méta-heuristique \textbf{GRASP\_LS} s'impose comme la méthode la plus performante. Sur les instances testées, elle atteint :
\begin{itemize}
    \item D'excellents résultats sur l'instance 17.in (2090)
    \item Le meilleur résultat sur l'instance 52.in (7777, soit 2.4\% mieux que LocalSearch)
    \item Le meilleur résultat sur l'instance 51.in (433)
\end{itemize}

\paragraph{Pour le compromis qualité/temps :} La \textbf{recherche locale 2-opt} offre le meilleur rapport performance/rapidité. Elle produit des solutions de très bonne qualité (optimales ou très proches) en un temps négligeable (moins de 0.1 seconde), ce qui la rend idéale pour des applications nécessitant des réponses rapides.

\newpage

\subsection{Validation sur Grande Instance (439.in)}

Le test complémentaire sur l'instance 439.in (439 villes) a permis de valider la robustesse des algorithmes face à des problèmes de taille réelle :

\begin{itemize}
    \item \textbf{Branch and Bound} : Inexploitable (Timeout).
    
    \item \textbf{Heuristique constructive} : Quasi-instantanée (0.09s).
    
    \item \textbf{LocalSearch (2-opt)} : Performance exceptionnelle (2.75s) pour une amélioration de 13.8\%. C'est l'algorithme le plus équilibré.
    
    \item \textbf{GRASP} : Excellente qualité (112\,265) en 317s, soit la meilleure solution trouvée sur cette instance.
\end{itemize}

\textbf{Conclusion du test 439.in :} L'implémentation retenue fournit des outils de production robustes et rapides.

\subsection{Recommandations Pratiques}

En fonction du contexte d'utilisation, nous recommandons :

\begin{itemize}
    \item \textbf{Instances très petites ($n < 20$)} : Utiliser Branch and Bound pour garantir l'optimalité
    \item \textbf{Instances moyennes ($20 \le n \le 100$)} : Utiliser LocalSearch pour un résultat rapide et relativement précis, ou GRASP pour la meilleure qualité
    \item \textbf{Grandes instances ($n > 100$)} : Privilégier LocalSearch pour sa robustesse et son efficacité ou utiliser GRASP avec un nombre d'itérations adapté pour sa justesse.
    \item \textbf{Applications temps réel} : Utiliser LocalSearch pour sa rapidité
\end{itemize}

\end{document}